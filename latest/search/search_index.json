{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome","text":""},{"location":"#welcome","title":"Welcome","text":"<p>steinbock is a toolkit for processing multiplexed tissue images</p> <p>The steinbock toolkit comprises the following components:</p> <ul> <li>The steinbock Python package with the integrated steinbock command-line interface (CLI)</li> <li>The steinbock Docker container interactively exposing the steinbock command-line interface, with supported third-party software (e.g. Ilastik, CellProfiler) pre-installed</li> </ul> <p>Modes of usage</p> <p>steinbock can be used both interactively using the command-line interface (CLI) and programmatically from within Python scripts.</p>"},{"location":"#overview","title":"Overview","text":"<p>At its core, steinbock provides the following functionality:</p> <ul> <li>Image preprocessing, including utilities for tiling/stitching images</li> <li>Pixel classification, to enable pixel classification-based image segmentation</li> <li>Image segmentation, to identify objects (e.g. cells or other regions of interest)</li> <li>Object measurement, to extract single-cell data, cell neighbors, etc.</li> <li>Data export, to facilitate downstream data analysis</li> <li>Visualization of multiplexed tissue images</li> </ul> <p>Downstream single-cell data analysis</p> <p>steinbock is a toolkit for extracting single-cell data from multiplexed tissue images and NOT for downstream single-cell data analysis.</p> <p>While all steinbock functionality can be used in a modular fashion, the toolkit was designed for - and explicitly supports - the following image segmentation workflows:</p> <ul> <li>[Ilastik/CellProfiler] Zanotelli et al. ImcSegmentationPipeline: A pixel classification-based multiplexed image segmentation pipeline. Zenodo, 2017. DOI: 10.5281/zenodo.3841961.</li> <li>[DeepCell/Mesmer] Greenwald et al. Whole-cell segmentation of tissue images with human-level performance using large-scale data annotation and deep learning. Nature Biotechnology, 2021. DOI: 10.1038/s41587-021-01094-0.</li> <li>[Cellpose] Stringer et al. Cellpose: a generalist algorithm for cellular segmentation. Nature methods, 2021. DOI: 10.1038/s41592-020-01018-x</li> </ul> <p>The steinbock toolkit is extensible and support for further workflows may be added in the future. If you are missing support for a workflow, please consider filing an issue on GitHub.</p>"},{"location":"#resources","title":"Resources","text":"<p>Code: https://github.com/BodenmillerGroup/steinbock</p> <p>Documentation: https://bodenmillergroup.github.io/steinbock</p> <p>Issue tracker: https://github.com/BodenmillerGroup/steinbock/issues</p> <p>Discussions: https://github.com/BodenmillerGroup/steinbock/discussions</p> <p>Workshop 2023: https://github.com/BodenmillerGroup/ImagingWorkshop2023</p>"},{"location":"#citing-steinbock","title":"Citing steinbock","text":"<p>Please cite the following paper when using steinbock in your work:</p> <p>Quote</p> <p>Windhager, J., Zanotelli, V.R.T., Schulz, D. et al. An end-to-end workflow for multiplexed image processing and analysis. Nat Protoc (2023). https://doi.org/10.1038/s41596-023-00881-0</p> <pre><code>@article{Windhager2023,\n  author = {Windhager, Jonas and Zanotelli, Vito R.T. and Schulz, Daniel and Meyer, Lasse and Daniel, Michelle and Bodenmiller, Bernd and Eling, Nils},\n  title = {An end-to-end workflow for multiplexed image processing and analysis},\n  year = {2023},\n  doi = {10.1038/s41596-023-00881-0},\n  URL = {https://www.nature.com/articles/s41596-023-00881-0},\n  journal = {Nature Protocols}\n}\n</code></pre> <p>If you have issues accessing the manuscript, please reach out to us and we can share the PDF version.</p>"},{"location":"authors/","title":"Authors","text":"<p>Created and maintained by Jonas Windhager until February 2023.</p> <p>Maintained by Milad Adibi from February 2023.</p>"},{"location":"changelog/","title":"Changelog","text":"<p>All notable changes to this project will be documented in this file.</p> <p>The format is based on Keep a Changelog, and this project adheres to Semantic Versioning.</p>"},{"location":"changelog/#0162-2023-08-15","title":"[0.16.2] - 2023-08-15","text":""},{"location":"changelog/#changed","title":"Changed","text":"<ul> <li>Enhanced error handling for missing ROIs #184</li> </ul>"},{"location":"changelog/#0161-2023-05-07","title":"0.16.1 - 2023-05-07","text":""},{"location":"changelog/#fixed","title":"Fixed","text":"<ul> <li>Broken external preprocessing for files with OME-suffix #181</li> </ul>"},{"location":"changelog/#0160-2023-02-03","title":"0.16.0 - 2023-02-03","text":""},{"location":"changelog/#added","title":"Added","text":"<ul> <li>New <code>steinbock view</code> command (napari) #27</li> <li>New <code>steinbock utils expand</code> command (mask expansion) #106</li> <li>New <code>steinbock apps jupyter</code> and <code>steinbock apps jupyterlab</code> commands</li> <li>New steinbock <code>-cellpose</code> container flavor (cellpose segmentation) #118</li> <li>New steinbock <code>-xpra</code> container flavor (web-based graphical user interfaces)</li> <li>Preparations for tensorflow-enabled arm64-based linux base images #98</li> <li>Added $RUN_FIXUID environment variable (prepare for Singularity) #156</li> </ul>"},{"location":"changelog/#changed_1","title":"Changed","text":"<ul> <li>Dependency upgrades</li> <li>CellProfiler upgrade to 4.2.5</li> <li>Harmonization of <code>--unzip</code> defaults (IMC preprocessing)</li> <li>Separate virtual environments for steinbock and CellProfiler</li> <li>Improved development environment (toolchain configuration, test skeletons)</li> <li>Revised steinbock Docker container installation instructions #160</li> </ul>"},{"location":"changelog/#fixed_1","title":"Fixed","text":"<ul> <li>Missing error message in measurement commands #151</li> </ul>"},{"location":"changelog/#0150-2022-09-15","title":"0.15.0 - 2022-09-15","text":"<ul> <li>#136 Fix histoCAT mask export</li> <li>#146 Fix relabeling during stitching</li> <li>Upgrade deepcell 0.12.2 to 0.12.3</li> <li>Upgrade CellProfiler 4.2.1 to 4.2.4</li> <li>Upgrade other dependencies</li> <li>#109 Support 2-6 channel TIFF files</li> <li>#66 Include panel/image metadata in anndata exports</li> <li>#117 Extract and process images from .zip archives file by file</li> <li>#104 #121 Documentation improvements</li> <li>#139 #140 #141 API improvements</li> </ul>"},{"location":"changelog/#0142-2022-06-29","title":"0.14.2 - 2022-06-29","text":"<ul> <li>Upgrade DeepCell (to 0.12.2) and other dependencies</li> <li>#132 Write images as ImageJ TIFF for supported data types only</li> <li>#133 Exclude hidden files from processing</li> </ul>"},{"location":"changelog/#0141-2022-06-08","title":"0.14.1 - 2022-06-08","text":"<ul> <li>#127 Fix CUDA build</li> <li>#128 Fix steinbock wheel</li> </ul>"},{"location":"changelog/#0140-2022-06-02","title":"0.14.0 - 2022-06-02","text":"<ul> <li>#111 Include package data in Python package</li> <li>#122 Use logging instead of <code>click.echo</code></li> <li>#123 Custom exception handling</li> <li>#124 Fix neighbor measurement</li> <li>#125 Upgrade to DeepCell 0.12.0</li> <li>Various minor bugfixes and improvements</li> <li>Upgrade all dependencies</li> </ul>"},{"location":"changelog/#0135-2022-02-21","title":"0.13.5 - 2022-02-21","text":"<ul> <li>Fix dependency version pinning</li> </ul>"},{"location":"changelog/#0134-2022-02-09","title":"0.13.4 - 2022-02-09","text":"<ul> <li>Fix DeepCell YAML loading</li> </ul>"},{"location":"changelog/#0133-2022-02-08","title":"0.13.3 - 2022-02-08","text":"<ul> <li>Fix ambiguous txt file matching (see #100)</li> </ul>"},{"location":"changelog/#0132-2022-02-04","title":"0.13.2 - 2022-02-04","text":"<ul> <li>Maintenance release</li> </ul>"},{"location":"changelog/#0131-2022-01-26","title":"0.13.1 - 2022-01-26","text":"<ul> <li>Fix GPU support</li> </ul>"},{"location":"changelog/#0130-2022-01-26","title":"0.13.0 - 2022-01-26","text":"<ul> <li>Full memory mapping support</li> <li>Fixed zero division error in deepcell normalization</li> <li>Added GPU support (switched to Ubuntu 18.04-based tensorflow base image)</li> <li>Fixed IMC panel preprocessing</li> <li>Upgraded dependencies</li> </ul>"},{"location":"changelog/#0120-2022-01-08","title":"0.12.0 - 2022-01-08","text":"<ul> <li>In-memory mosaics</li> <li>Stabilized image/mask IO</li> <li>Standardized command output</li> <li>Minor changes, documentation</li> </ul>"},{"location":"changelog/#0110-2021-12-28","title":"0.11.0 - 2021-12-28","text":"<ul> <li>Removed steinbock version check</li> <li>Fix IMC panel preprocessing (channel order)</li> <li>Make CLI usable when using PyPI package install</li> <li>Renamed <code>--mask</code> and <code>--probab</code> parameters to <code>--masks</code> and <code>--probabs</code>, respectively</li> <li>Clean histoCAT export file names</li> <li>Required <code>-o</code> parameter for data export</li> </ul>"},{"location":"changelog/#0107-2021-12-27","title":"0.10.7 - 2021-12-27","text":"<ul> <li>Fix IMC panel preprocessing</li> </ul>"},{"location":"changelog/#0106-2021-12-27","title":"0.10.6 - 2021-12-27","text":"<ul> <li>Customizable IMC panel columns</li> </ul>"},{"location":"changelog/#0105-2021-12-25","title":"0.10.5 - 2021-12-25","text":"<ul> <li>Fix IMC panel preprocessing</li> </ul>"},{"location":"changelog/#0104-2021-12-25","title":"0.10.4 - 2021-12-25","text":"<ul> <li>Fix IMC panel preprocessing</li> </ul>"},{"location":"changelog/#0103-2021-12-20","title":"0.10.3 - 2021-12-20","text":"<ul> <li>Fix memory issue with Ilastik image creation</li> </ul>"},{"location":"changelog/#0102-2021-12-07","title":"0.10.2 - 2021-12-07","text":"<ul> <li>Fix deepcell incompatibility with scikit-image upgrade</li> </ul>"},{"location":"changelog/#0101-2021-12-06","title":"0.10.1 - 2021-12-06","text":"<ul> <li>Fix AnnData export warning</li> <li>Allow duplicated txt/mcd file names</li> <li>Upgrade readimc and other dependencies</li> </ul>"},{"location":"changelog/#0100-2021-11-05","title":"0.10.0 - 2021-11-05","text":"<ul> <li>Unified object data (csv, fcs, anndata) export commands</li> <li>Improved anndata export: concatenation, intensities, graphs</li> <li>Improved IMC panel preprocessing: support for different panels</li> <li>Added functionality for importing image data using imageio</li> <li>Clean up and upgrade dependencies, including deepcell 0.11.0</li> <li>Change image file name pattern to make acquisitions sortable</li> <li>Upgrade readimc for faster reading of .txt files</li> <li>Change CellProfiler input image dtype to uint16</li> <li>Change histoCAT mask dtype to uint16</li> <li>Updated documentation on Docker</li> </ul>"},{"location":"changelog/#091-2021-10-12","title":"0.9.1 - 2021-10-12","text":"<ul> <li>Fixed preprocessing of IMC Segmentation Pipeline panels</li> </ul>"},{"location":"changelog/#090-2021-10-11","title":"0.9.0 - 2021-10-11","text":"<ul> <li>Upgraded dependencies</li> <li>Improved documentation</li> <li>Reduced Docker image size</li> <li>Replaced imctools with readimc</li> <li>Added dockerized unit tests (w.i.p.)</li> <li>Restructured package, renamed tools to utils</li> <li>Updated package information, added <code>all</code> extra</li> <li>Added histoCAT image export command</li> <li>Added steinbock logo (Nils Eling)</li> </ul>"},{"location":"changelog/#081-2021-09-22","title":"0.8.1 - 2021-09-22","text":"<ul> <li>Added missing deepcell column to IMC panel preprocessing from raw data</li> </ul>"},{"location":"changelog/#080-2021-09-21","title":"0.8.0 - 2021-09-21","text":"<ul> <li>Improved error handling &amp; messages</li> <li>Restructured &amp; improved documentation</li> <li>IMC preprocessing: extract image metadata</li> <li>Fix steinbock versioning in docker container</li> <li>Upgraded dependencies, including deepcell 0.10.0</li> <li>Fix permission issues using fixuid approach</li> </ul>"},{"location":"changelog/#073-2021-09-09","title":"0.7.3 - 2021-09-09","text":"<ul> <li>Make container ready for passwd mounting</li> <li>Fix OME export destination directory name</li> </ul>"},{"location":"changelog/#072-2021-09-09","title":"0.7.2 - 2021-09-09","text":"<ul> <li>Fixed graph export</li> </ul>"},{"location":"changelog/#071-2021-09-09","title":"0.7.1 - 2021-09-09","text":"<ul> <li>Renamed graph measurement to neighbor measurement</li> </ul>"},{"location":"changelog/#070-2021-09-01","title":"0.7.0 - 2021-09-01","text":"<ul> <li>Improved graph construction performance</li> <li>Added new graph construction methods, including pixel expansion</li> <li>Removed distance computation in favor of more performant graph construction</li> <li>Fixed IMC panel preprocessing (unreported bugs)</li> <li>Fixed Ilastik pixel classification (unreported bugs)</li> </ul>"},{"location":"changelog/#062-2021-08-21","title":"0.6.2 - 2021-08-21","text":"<ul> <li>Improved documentation &amp; switched to versioned documentation</li> <li>Improved IMC Segmentation Pipeline panel support (#38)</li> </ul>"},{"location":"changelog/#061-2021-08-17","title":"0.6.1 - 2021-08-17","text":"<ul> <li>Fixed data type conversion upon image loading</li> </ul>"},{"location":"changelog/#060-2021-08-17","title":"0.6.0 - 2021-08-17","text":"<ul> <li>Updated CellProfiler and other dependencies (#22)</li> <li>Switch from Docker Hub to GitHub Container Registry (#34)</li> <li>Various compatibility improvements and bugfixes (#21, #28, #32, #35)</li> </ul>"},{"location":"changelog/#056-2021-06-29","title":"0.5.6 - 2021-06-29","text":"<ul> <li>Switch to bilinear interpolation for Ilastik mean channel</li> <li>Make image/mask data type configurable via environment variables</li> </ul>"},{"location":"changelog/#055-2021-06-28","title":"0.5.5 - 2021-06-28","text":"<ul> <li>Fix steinbock version check</li> <li>Add meanfactor option to Ilastik (compatibility with IMC segmentation pipeline)</li> <li>Save Ilastik images/crops as uint16 (compatibility with IMC segmentation pipeline)</li> </ul>"},{"location":"changelog/#054-2021-06-23","title":"0.5.4 - 2021-06-23","text":"<ul> <li>Speed up Ilastik image creation</li> </ul>"},{"location":"changelog/#053-2021-06-22","title":"0.5.3 - 2021-06-22","text":"<ul> <li>Fix CSV/FCS export</li> </ul>"},{"location":"changelog/#052-2021-06-15","title":"0.5.2 - 2021-06-15","text":"<ul> <li>Fix networkx node attribute export</li> <li>Remove <code>object_</code> prefix from default directory names</li> <li>Speed up intensity measurement (use scipy.ndimage for aggregation)</li> </ul>"},{"location":"changelog/#051-2021-06-10","title":"0.5.1 - 2021-06-10","text":"<ul> <li>Version bumps of tifffile, xtiff</li> <li>Preprocessing/postprocessing parameter support for DeepCell</li> </ul>"},{"location":"changelog/#050-2021-06-03","title":"0.5.0 - 2021-06-03","text":"<ul> <li>Module restructuring</li> <li>PyPI package release</li> <li>CLI refactoring, --version option</li> <li>Improved documentation (API documentation is w.i.p.)</li> <li>Export to OME-TIFF, CSV, FCS, AnnData, graph file formats</li> <li>Match related files by name rather than alphabetical order</li> <li>Customizable pixel/channel aggregation strategies</li> <li>Many more small bug fixes &amp; improvements</li> </ul>"},{"location":"changelog/#040-2021-05-27","title":"0.4.0 - 2021-05-27","text":"<ul> <li>Python API cleanup</li> <li>Added DeepCell segmentation support</li> </ul>"},{"location":"changelog/#037-2021-05-20","title":"0.3.7 - 2021-05-20","text":"<ul> <li>Automatic SCM versioning</li> <li>Steinbock version file checks</li> <li>Renamed steinbock panel columns</li> <li>Improved Docker container Python package setup</li> <li>Combined kNN/distance-thresholded graph generation</li> </ul>"},{"location":"changelog/#036-2021-04-29","title":"0.3.6 - 2021-04-29","text":"<ul> <li>Make panel channel label values optional</li> <li>Rename panel columns metal, name to id, label</li> </ul>"},{"location":"changelog/#035-2021-04-29","title":"0.3.5 - 2021-04-29","text":"<ul> <li>Minor bug fixes and performance improvements</li> <li>Separated IMC panel/image preprocessing to allow for easier channel filtering</li> </ul>"},{"location":"changelog/#034-2021-04-27","title":"0.3.4 - 2021-04-27","text":"<ul> <li>#6 Panel creation from .mcd/.txt files</li> <li>#9 Improved documentation on Ilastik feature selection</li> <li>#10 Fixed Ilastik class label colors</li> <li>#11 Simplified command-line interface</li> </ul>"},{"location":"changelog/#033-2021-04-21","title":"0.3.3 - 2021-04-21","text":"<p>New functionality, bug fixes, documentation improvements</p> <p>Added:</p> <ul> <li>ZIP archive support for IMC data (closes #2)</li> <li>Ilastik channel ordering &amp; grouping (closes #3)</li> <li>Run container as non-privileged user (fixes #4)</li> </ul>"},{"location":"changelog/#032-2021-04-19","title":"0.3.2 - 2021-04-19","text":"<p>New functionality, bug fixes, documentation improvements</p> <p>Added:</p> <ul> <li>Mask matching</li> <li>IMC panel pass-through</li> <li>Generalized object segmentation</li> <li>Hardened image loading to allow for tiles of size 1 in one dimension</li> </ul>"},{"location":"changelog/#031-2021-04-18","title":"0.3.1 - 2021-04-18","text":"<p>Documentation, minor improvements, fix memory leaks &amp; stitching</p>"},{"location":"changelog/#030-2021-04-16","title":"0.3.0 - 2021-04-16","text":"<p>CLI refactoring, mosaic tooling</p>"},{"location":"changelog/#020-2021-04-12","title":"0.2.0 - 2021-04-12","text":"<p>CLI refactoring, removed imctoolkit dependency</p> <p>Added:</p> <ul> <li>Support for \"raw\" IMC panels</li> <li>Additional user input validation</li> <li>Mean channel in Ilastik images/crops</li> <li>Additional progress bars/indicators</li> <li>Measurements for cell regionprops</li> <li>Measurements for cell distances/graphs</li> </ul>"},{"location":"changelog/#010-2021-04-08","title":"0.1.0 - 2021-04-08","text":"<p>Initial release for beta testing</p>"},{"location":"contributing/","title":"Contributing","text":"<p>Pull requests are welcome. Please make sure to update tests and documentation as appropriate.</p> <p>For major changes, please open an issue first to discuss what you would like to change.</p>"},{"location":"contributing/#toolchain","title":"Toolchain","text":"<p>steinbock is developed using Visual Studio Code. The Python development toolchain includes black, flake8, isort, mypy and pre-commit (see setuptools <code>devel</code> target). For building the steinbock Docker image, BuildKit needs to be enabled for Docker. Workflows for continuous integration/continuous delivery (CI/CD) are configured using GitHub Actions.</p>"},{"location":"contributing/#development","title":"Development","text":"<p>For convenience, the following Docker Compose services are available:</p> <ul> <li><code>steinbock</code> for running steinbock</li> <li><code>steinbock-debug</code> for debugging steinbock using debugpy</li> <li><code>pytest</code> for running unit tests with pytest</li> <li><code>pytest-debug</code> for debugging unit tests with pytest and debugpy</li> </ul> <p>Matching Visual Studio Code launch configurations are provided for debugging:</p> <ul> <li><code>Docker: Python General</code> for debugging steinbock using Docker directly</li> <li><code>Python: Remote Attach (steinbock-debug)</code> for debugging steinbock using Docker Compose</li> <li><code>Python: Remote Attach (pytest-debug)</code> for debugging unit tests with pytest using Docker Compose</li> </ul> <p>To debug specific steinbock commands using e.g. the <code>Python: Remote Attach (steinbock-debug)</code> launch configuration, adapt the respective <code>command</code> in the docker-compose.yml file (e.g. add <code>--version</code> after <code>-m steinbock</code>). Launch configurations may have to be invoked multiple times in order for them to work.</p> <p>To debug unit tests on the host system (i.e., not within the Docker container), run <code>pytest tests</code> in the project root folder or use the \"Testing\" tab in Visual Studio Code.</p>"},{"location":"contributors/","title":"Contributors","text":""},{"location":"contributors/#nils-eling","title":"Nils Eling","text":"<p>nils.eling@uzh.ch</p> <ul> <li>Logo</li> <li>Documentation</li> <li>Testing, feedback &amp; discussion</li> </ul>"},{"location":"directories/","title":"Directories","text":"<p>The input and output files and directories of all steinbock CLI commands can be controlled via command-line options. However, without explicitly specifying input/output arguments, the following typical directory structure is assumed when working with the steinbock CLI:</p> <pre><code>steinbock data/working directory\n|\n\u251c\u2500\u2500 raw                       (user-provided, when starting from raw data)\n|\n\u251c\u2500\u2500 img                       (user-provided, when not starting from raw data)\n\u251c\u2500\u2500 panel.csv                 (user-provided, when not starting from raw data)\n\u251c\u2500\u2500 images.csv\n|\n\u251c\u2500\u2500 ilastik_img\n\u251c\u2500\u2500 ilastik_crops\n\u251c\u2500\u2500 pixel_classifier.ilp\n\u251c\u2500\u2500 ilastik_probabilities\n|\n\u251c\u2500\u2500 cell_segmentation.cppipe\n\u251c\u2500\u2500 masks\n|\n\u251c\u2500\u2500 intensities\n\u251c\u2500\u2500 regionprops\n\u2514\u2500\u2500 neighbors\n</code></pre> <p>Depending on the choice of preprocessing approaches, either the <code>raw</code> directory containing the raw data, or the <code>img</code> directory containing the images and a <code>panel.csv</code> file must be provided by the user. All other files and directories are generated by the steinbock Docker container when following a supported workflow.</p>"},{"location":"file-types/","title":"File types","text":""},{"location":"file-types/#panel","title":"Panel","text":"<p>File extension: .csv</p> <p>User-provided list of channels present in the images (in order)</p> <p>Comma-separated values (CSV) file with column headers and no index</p> Column Description Type Required? <code>channel</code> Unique channel ID, e.g. metal isotope Text yes <code>name</code> Unique channel name, e.g. antibody target(can be empty only for rows with <code>keep=0</code>) Text or empty yes <code>keep</code> Whether the channel is present in preprocessed images(if column is absent, all channels are assumed present) Boolean (<code>0</code> or <code>1</code>) no <code>ilastik</code> Group label for creating steinbock Ilastik images(if column is absent, all channels are used separately) Numeric or empty no <code>deepcell</code> Group label for DeepCell segmentation(if column is absent, all channels are used separately) Numeric or empty no <code>cellpose</code> Group label for Cellpose segmentation(if column is absent, all channels are used separately) Numeric or empty no <p>The steinbock panel allows for further arbitrary columns.</p>"},{"location":"file-types/#images","title":"Images","text":"<p>File extension: .tiff</p> <p>Multi-channel images, where each channel corresponds to a panel entry</p> <p>Tag Image File Format (TIFF) images of any data type in CYX dimension order</p> <p>Image data type</p> <p>Unless explicitly mentioned, images are converted to 32-bit floating point upon loading (without rescaling).</p>"},{"location":"file-types/#image-information","title":"Image information","text":"<p>File extension: .csv</p> <p>Image information (e.g. image dimensions) extracted during preprocessing</p> <p>CSV file with image file name as index (<code>Image</code> column) and the following columns:</p> Column Description Type <code>image</code> Unique image file name Text <code>width_px</code> Image width, in pixels Numeric <code>height_px</code> Image height, in pixels Numeric <code>num_channels</code> Number of image channels Numeric <p>Further columns may be added by modality-specific preprocessing commands.</p>"},{"location":"file-types/#probabilities","title":"Probabilities","text":"<p>File extension: .tiff</p> <p>Color images, with one color per class encoding the probability of pixels belonging to that class</p> <p>16-bit unsigned integer TIFF images in YXS dimension order, same YX ratio as source image</p> <p>Probability image size</p> <p>The size of probability images may be different from the original images (see Ilastik pixel classification).</p>"},{"location":"file-types/#object-masks","title":"Object masks","text":"<p>File extension: .tiff</p> <p>Grayscale images, with one unique value per object (\"object ID\", 0 for background)</p> <p>16-bit unsigned integer TIFF images in YX dimension order, same YX shape as source image</p>"},{"location":"file-types/#object-data","title":"Object data","text":"<p>File extension: .csv</p> <p>Object measurements (e.g. mean intensities, morphological features)</p> <p>CSV file with object IDs as index (<code>Object</code> column) and feature/channel names as columns</p> <p>Combined object data</p> <p>For data containing measurements from multiple images, a combined index of image name and object ID is used.</p>"},{"location":"file-types/#object-neighbors","title":"Object neighbors","text":"<p>File extension: .csv</p> <p>List of directed edges defining a spatial object neighborhood graph</p> <p>CSV file (one per image) with no index and three columns (<code>Object</code>, <code>Neighbor</code>, <code>Distance</code>)</p> <p>Undirected graphs</p> <p>For undirected graphs, each edge appears twice (one edge per direction)</p>"},{"location":"install-docker/","title":"Docker container","text":"<p>The steinbock toolkit can be used interactively using the steinbock Docker container.</p> <p>In this section, the installation and configuration of the steinbock Docker container is described.</p>"},{"location":"install-docker/#prerequisites","title":"Prerequisites","text":""},{"location":"install-docker/#windows","title":"Windows","text":"<p>Install Docker Desktop</p> <p>Make sure to NOT skip step 5 of the interactive installation instructions (adding your user to the docker-users group, if necessary).</p> <p>Docker Desktop can run in either Hyper-V mode or in WSL 2 mode. To check/choose in which mode Docker Desktop is running, refer to the preferences menu as described here (Docker Preferences --&gt; General --&gt; Use the WSL 2 based engine). In general, it is recommended to run Docker Desktop in WSL 2 mode for performance reasons, see here.</p> <p>Systems with limited memory resources</p> <p>On systems with limited memory resources, due to a problem with WSL 2, it may still be advisable to use the Hyper-V mode. This may also be the case if you experience performance losses due to slow disk access (see here)</p> <p>Make sure to allocate enough system resources to Docker, as the default memory limit of 2GB will likely not be sufficient to run steinbock on real-world datasets:</p> <ul> <li> <p>If and only if Docker Desktop is running in Hyper-V mode, configure the memory that Docker Desktop is allowed to use as described here (Docker Preferences --&gt; Resources --&gt; Advanced --&gt; Memory).</p> </li> <li> <p>If and only if Docker Desktop is running in WSL 2 mode, follow the instructions for changing global configuration options to configure the memory that Docker Desktop is allowed to use.</p> </li> </ul> <p>For any subsequent instruction, use the Windows Command Prompt (not the Windows PowerShell).</p>"},{"location":"install-docker/#mac-os","title":"Mac OS","text":"<p>steinbock on ARM-based Macs</p> <p>The steinbock Docker container currently does not fully work on ARM-based Macs (e.g. M1, M2).</p> <p>Install Docker Desktop</p> <p>Make sure to allocate enough system resources to Docker, as the default memory limit of 2GB will likely not be sufficient to run steinbock on real-world datasets. In order to do so, configure the memory that Docker Desktop is allowed to use as described here (Docker Preferences --&gt; Resources --&gt; Advanced --&gt; Memory).</p> <p>For any subsequent instruction, use the Mac OS Terminal.</p>"},{"location":"install-docker/#linux","title":"Linux","text":"<p>Install Docker Server/Engine</p> <p>Follow the post-installation steps for Linux</p> <p>To run the steinbock Docker container with NVIDIA GPU support (optional), install the proper drivers and verify that your GPU is running and accessible. Install the <code>nvidia-container-runtime</code> as described here and restart your system.</p> <p>For any subsequent instruction, use the Linux Terminal.</p>"},{"location":"install-docker/#installation","title":"Installation","text":"<p>In principle, the steinbock Docker container can be run on any Docker-enabled platform:</p> <pre><code>docker run ghcr.io/bodenmillergroup/steinbock\n</code></pre> <p>For reproducibility, it is recommended to always pull a specific release, e.g.:</p> <pre><code>docker run ghcr.io/bodenmillergroup/steinbock:0.16.1\n</code></pre> <p>To run the steinbock Docker container with NVIDIA GPU support (Linux only):</p> <pre><code>docker run --gpus all ghcr.io/bodenmillergroup/steinbock:0.16.1-gpu\n</code></pre> <p>Bind mounts can be used to make data from the host system available to the Docker container (see below). Commands that launch a graphical user interface may require further system configuration and additional arguments to <code>docker run</code> as outlined in the following.</p>"},{"location":"install-docker/#windows_1","title":"Windows","text":"<p>On the command line, use the following command to run the steinbock Docker container:</p> <pre><code>docker run -v \"C:\\Data\":/data -p 8888:8888 -e DISPLAY=host.docker.internal:0 ghcr.io/bodenmillergroup/steinbock:0.16.1\n</code></pre> <p>In the command above, adapt the bind mount path to your data/working directory (<code>C:\\Data</code>; no trailing backslash) and the steinbock Docker container version (<code>0.16.1</code>) as needed. Specifying the <code>DISPLAY</code> environment variable is required only when running graphical user interfaces using X forwarding.</p> <p>To simplify the use of the steinbock command-line interface, it is recommended to set up a <code>steinbock</code> macro:</p> <pre><code>doskey steinbock=docker run -p 8888:8888 -v \"C:\\Data\":/data ghcr.io/bodenmillergroup/steinbock:0.16.1 $*\n</code></pre> <p>The created macro is retained for the current session and enables running <code>steinbock</code> from the current command line without typing the full Docker command, for example:</p> <pre><code>steinbock --version\n</code></pre> <p>Graphical user interfaces on Windows</p> <p>To allow the steinbock Docker container to run graphical user interfaces (e.g. Ilastik, CellProfiler, napari) using X forwarding, VcXsrv is required. Running steinbock with VcXsrv is untested and therefore undocumented; please do not hesitate to file a GitHub issue if you would like to contribute to this documentation.</p>"},{"location":"install-docker/#mac-os_1","title":"Mac OS","text":"<p>On the terminal, use the following command to run the steinbock Docker container (Docker must be running):</p> <pre><code>docker run -v /path/to/data:/data --platform linux/amd64 -u $(id -u):$(id -g) -p 8888:8888 -v /tmp/.X11-unix:/tmp/.X11-unix -v ~/.Xauthority:/home/steinbock/.Xauthority:ro -e DISPLAY=host.docker.internal:0 ghcr.io/bodenmillergroup/steinbock:0.16.1\n</code></pre> <p>In the command above, adapt the bind mount path to your data/working directory (<code>/path/to/data</code>) and the steinbock Docker container version (<code>0.16.1</code>) as needed. Specifying the <code>/tmp/.X11-unix</code> bind mount, the <code>~/.Xauthority</code> bind mount and the <code>DISPLAY</code> environment variable are required only when running graphical user interfaces using X forwarding.</p> <p>To simplify the use of the steinbock command-line interface, it is recommended to set up a <code>steinbock</code> command alias:</p> <pre><code>alias steinbock=\"docker run -v /path/to/data:/data --platform linux/amd64 -u $(id -u):$(id -g) -p 8888:8888 -v /tmp/.X11-unix:/tmp/.X11-unix -v ~/.Xauthority:/home/steinbock/.Xauthority:ro -e DISPLAY=host.docker.internal:0 ghcr.io/bodenmillergroup/steinbock:0.16.1\"\n</code></pre> <p>The created command alias is retained for the current session and enables running <code>steinbock</code> from the current terminal without typing the full Docker command, for example:</p> <pre><code>steinbock --version\n</code></pre> <p>Graphical user interfaces on Mac OS</p> <p>To allow the steinbock Docker container to run graphical user interfaces (e.g. Ilastik, CellProfiler, napari) using X forwarding, first install and launch XQuartz. Then, open XQuartz &gt; Security &gt; Preferences and tick Allow connections from network clients. Log out of your user account and login again; restart Docker and XQuartz. Finally, to allow the local root user (i.e., the user running the Docker daemon) to access the running XQuartz X server:</p> <pre><code>xhost +localhost\n</code></pre>"},{"location":"install-docker/#linux_1","title":"Linux","text":"<p>On the terminal, use the following command to run the steinbock Docker container:</p> <pre><code>docker run -v /path/to/data:/data -u $(id -u):$(id -g) --network host -v /tmp/.X11-unix:/tmp/.X11-unix -e DISPLAY ghcr.io/bodenmillergroup/steinbock:0.16.1\n</code></pre> <p>To run the steinbock Docker container with NVIDIA GPU support, use <code>-gpu</code> Docker image instead:</p> <pre><code>docker run -v /path/to/data:/data -u $(id -u):$(id -g) --network host -v /tmp/.X11-unix:/tmp/.X11-unix -e DISPLAY --gpus all ghcr.io/bodenmillergroup/steinbock:0.16.1-gpu\n</code></pre> <p>In the commands above, adapt the bind mount path to your data/working directory (<code>/path/to/data</code>) and the steinbock Docker container version (<code>0.16.1</code>) as needed. Specifying the <code>host</code> network mode, the <code>/tmp/.X11-unix</code> bind mount and the <code>DISPLAY</code> environment variable are required only when running graphical user interfaces using X forwarding.</p> <p>To simplify the use of the steinbock command-line interface, it is recommended to set up a <code>steinbock</code> command alias:</p> <pre><code>alias steinbock=\"docker run -v /path/to/data:/data -u $(id -u):$(id -g) --network host -v /tmp/.X11-unix:/tmp/.X11-unix -e DISPLAY ghcr.io/bodenmillergroup/steinbock:0.16.1\"\n</code></pre> <p>To run the steinbock Docker container with NVIDIA GPU support, use <code>-gpu</code> Docker image instead:</p> <pre><code>alias steinbock=\"docker run -v /path/to/data:/data -u $(id -u):$(id -g) --network host -v /tmp/.X11-unix:/tmp/.X11-unix -e DISPLAY --gpus all ghcr.io/bodenmillergroup/steinbock:0.16.1-gpu\"\n</code></pre> <p>The created command alias is retained for the current session and enables running <code>steinbock</code> from the current terminal without typing the full Docker command, for example:</p> <pre><code>steinbock --version\n</code></pre> <p>Graphical user interfaces on Linux</p> <p>To allow the steinbock Docker container to run graphical user interfaces (e.g. Ilastik, CellProfiler, napari) using X forwarding, if necessary, allow the local root user to access the running X server:</p> <pre><code>xhost +local:root\n</code></pre>"},{"location":"install-docker/#usage","title":"Usage","text":"<p>Please refer to command-line usage for usage instructions.</p> <p>Getting help</p> <p>The steinbock Docker container is under active development. If you are experiencing issues, you are more than welcome to file an issue on GitHub. However, please understand that only issues directly concerning steinbock can be addressed. For user support with Docker, command line usage, etc., please refer to your local IT administrator.</p>"},{"location":"install-python/","title":"Python package","text":"<p>The steinbock toolkit can be used programmatically using the steinbock Python package.</p> <p>In this section, the installation of the steinbock Python package is described.</p> <p>For scripting use only</p> <p>Installing/using the steinbock Python package directly is not recommended for regular users. Please use the steinbock Docker containers instead.</p>"},{"location":"install-python/#requirements","title":"Requirements","text":"<p>Python 3.8 or newer</p> <p>Tested versions of Python package dependencies can be found in requirements.txt.</p>"},{"location":"install-python/#installation","title":"Installation","text":"<p>The steinbock Python package can be installed from PyPI as follows:</p> <pre><code>pip install steinbock\n</code></pre> <p>The following extras are available:</p> <ul> <li><code>imc</code> to enable IMC preprocessing functionality</li> <li><code>deepcell</code> to enable DeepCell segmentation functionality</li> <li><code>cellpose</code> to enable Cellpose segmentation functionality</li> <li><code>napari</code> to enable image visualization functionality</li> </ul>"},{"location":"install-python/#usage","title":"Usage","text":"<p>Please refer to Python usage for usage instructions.</p>"},{"location":"license/","title":"License","text":"<p>Copyright (c) 2021 University of Zurich</p> <p>steinbock is licensed under the MIT License</p> <p>https://github.com/BodenmillerGroup/steinbock/blob/main/LICENSE</p>"},{"location":"cli/apps/","title":"Apps","text":"<p>The steinbock Docker container exposes various third-party apps via the <code>apps</code> command.</p>"},{"location":"cli/apps/#ilastik","title":"Ilastik","text":"<p>Docker and graphical user interfaces</p> <p>Running Ilastik using steinbock Docker containers requires support for graphical user interfaces (e.g. X forwarding).</p> <p>To run Ilastik:</p> <pre><code>steinbock apps ilastik\n</code></pre> <p>Without additional arguments, this will start the graphical user interface of Ilastik.</p>"},{"location":"cli/apps/#cellprofiler","title":"CellProfiler","text":"<p>Docker and graphical user interfaces</p> <p>Running CellProfiler using steinbock Docker containers requires support for a graphical user interfaces (e.g. X forwarding).</p> <p>To run CellProfiler:</p> <pre><code>steinbock apps cellprofiler\n</code></pre> <p>Without additional arguments, this will start the graphical user interface of CellProfiler.</p>"},{"location":"cli/apps/#jupyter-notebook","title":"Jupyter Notebook","text":"<p>Port</p> <p>Jupyter Notebook requires the specified port exposed and published via Docker.</p> <p>To run Jupyter Notebook:</p> <pre><code>steinbock apps jupyter\n</code></pre> <p>Without additional arguments, this will start Jupyter Notebook on http://localhost:8888.</p>"},{"location":"cli/apps/#jupyter-lab","title":"Jupyter Lab","text":"<p>Port</p> <p>Jupyter Lab requires the specified port exposed and published via Docker.</p> <p>To run Jupyter Lab:</p> <pre><code>steinbock apps jupyterlab\n</code></pre> <p>Without additional arguments, this will start Jupyter Lab on http://localhost:8888.</p>"},{"location":"cli/classification/","title":"Pixel classification","text":"<p>In this step, for each image, the probabilities of pixels belonging to a given class (e.g. nucleus, cytoplasm, background) will be determined. This will result in probability images, with one color per class encoding the probability of pixels belonging to that class (see File types).</p> <p>Pixel classification-based image segmentation</p> <p>Probability images generated by pixel classification can be used to segment images, see Object segmentation.</p> <p>Various classification approaches are supported, each of which is described in the following.</p>"},{"location":"cli/classification/#ilastik","title":"Ilastik","text":"<p>Ilastik is an application for interactive learning and segmentation. Here, Ilastik's semantic pixel classification workflow is used to perform pixel classification using random forests.</p>"},{"location":"cli/classification/#data-preparation","title":"Data preparation","text":"<p>In a first step, input data are prepared for processing with Ilastik:</p> <pre><code>steinbock classify ilastik prepare --cropsize 50 --seed 123\n</code></pre> <p>With default desination file/directory paths shown in brackets, this will:</p> <ul> <li>aggregate, scale and convert images to steinbock Ilastik format (<code>ilastik_img</code>)</li> <li>extract and save one random crop of 50x50 pixels per image for training (<code>ilastik_crops</code>)</li> <li>create a default steinbock Ilastik pixel classification project file (<code>pixel_classifier.ilp</code>)</li> </ul> <p>By specifying the <code>--seed</code> parameter, this command reproducibly extracts crops from the same pseudo-random locations when executed repeatedly.</p> <p>Ilastik image data</p> <p>All generated image data are saved in steinbock Ilastik HDF5 format (undocumented).</p> <p>If an <code>ilastik</code> column is present in the steinbock panel file, channels are sorted and grouped according to values in that column: For each image, each group of channels is aggregated by computing the mean along the channel axis (use the <code>--aggr</code> option to specify a different aggregation strategy). The generated Ilastik images consist of one channel per group; channels without a group label are ignored. In addition, the mean of all included channels is prepended to the generated Ilastik images as an additional channel, unless <code>--no-mean</code> is specified.</p> <p>Furthermore, all generated Ilastik images are scaled two-fold in x and y, unless specified otherwise using the <code>--scale</code> command-line option. This helps with more accurately identifying object borders in segmentation workflows for images of relatively low resolution (e.g. Imaging Mass Cytometry). In applications with higher resolution (e.g. sequential immunofluorescence), it is recommended to not scale the image data, i.e., to specify <code>--scale 1</code>.</p>"},{"location":"cli/classification/#training-the-classifier","title":"Training the classifier","text":"<p>To interactively train a new classifier, open the pixel classification project in Ilastik (see Apps):</p> <pre><code>steinbock apps ilastik\n</code></pre> <p>Data/working directory</p> <p>Within the container, your data/working directory containing the Ilastik project file is accessible under <code>/data</code>.</p> <p>More detailed instructions on how to use Ilastik for training a pixel classifier can be found here.</p> <p>Class labels for segmentation</p> <p>By default, the Ilastik pixel classification project is configured for training three classes (Nucleus, Cytoplasm, Background) for cell segmentation. Other segmentation workflows may require different numbers of classes and class labels (e.g. two classes for Tumor/Stroma segmentation). While the number and order of classes is arbitrary and can be changed by the user, it needs to be compatible with downstream segmentation steps.</p> <p>Feature selection</p> <p>The choice of features in Ilastik's feature selection step depends on the input data. For relatively small IMC datasets, the selection of all default features greater than or equal to 1 pixel is recommended.</p>"},{"location":"cli/classification/#existing-training-data","title":"Existing training data","text":"<p>Experimental feature</p> <p>Reusing existing training data is an experimental feature. Use at own risk. Always make backups of your data.</p> <p>Instead of training a new classifier, one can use an existing classifier by</p> <ul> <li> <p>replacing the generated Ilastik pixel classification project file with a pre-trained project, and</p> </li> <li> <p>replacing the image crops (see Data preparation) with the crops originally used for training.</p> </li> </ul> <p>Subsequently, to ensure compatibility of the external Ilastik project file/crops:</p> <pre><code>steinbock classify ilastik fix\n</code></pre> <p>This will attempt to in-place patch the Ilastik pixel classification project and the image crops after creating a backup (<code>.bak</code> file/directory extension), unless <code>--no-backup</code> is specified.</p> <p>Patching existing training data</p> <p>This command will convert image crops to 32-bit floating point images with CYX dimension order and save them in steinbock Ilastik HDF5 format (undocumented). It will then adjust the metadata in the Ilastik project file accordingly.</p>"},{"location":"cli/classification/#batch-processing","title":"Batch processing","text":"<p>After training the pixel classifier on the image crops (or providing and patching a pre-trained one), it can be applied to a batch of full-size images created in the Data preparation step as follows:</p> <pre><code>steinbock classify ilastik run\n</code></pre> <p>By default, this will create probability images in <code>ilastik_probabilities</code>, with one color per class encoding the probability of pixels belonging to that class (see File types).</p> <p>Probability images</p> <p>The size of the generated probability images are equal to the size of the Ilastik input images, i.e., scaled by a user-specified factor that defaults to 2 (see above). If applicable, make sure to adapt downstream segmentation workflows accordingly to create object masks matching the original (i.e., unscaled) images.</p> <p>If the default three-class structure is used, the probability images are RGB images with the following color code:</p> <ul> <li>Red: Nuclei</li> <li>Green: Cytoplasm</li> <li>Blue: Background</li> </ul>"},{"location":"cli/export/","title":"Data export","text":"<p>Data generated by steinbock can be exported to various formats for downstream data analysis.</p>"},{"location":"cli/export/#ome-tiff","title":"OME-TIFF","text":"<p>To export images to OME-TIFF, with channel names determined by the panel file:</p> <pre><code>steinbock export ome\n</code></pre> <p>The exported OME-TIFF files are generated by xtiff; the default destination directory is <code>ome</code>.</p>"},{"location":"cli/export/#histocat","title":"histoCAT","text":"<p>To export images and masks to a folder structure compatible with histoCAT for MATLAB:</p> <pre><code>steinbock export histocat\n</code></pre> <p>This will create a histoCAT-compatible folder structure (defaults to <code>histocat</code>), with one subfolder per image, where each subfolder contains one image file per channel. Additionally, if masks are available, each image subfolder contains a single mask file.</p>"},{"location":"cli/export/#csv","title":"CSV","text":"<p>To export specified object data from all images as a single .csv file:</p> <pre><code>steinbock export csv intensities regionprops -o objects.csv\n</code></pre> <p>This will collect object data from the <code>intensities</code> and <code>regionprops</code> directories and create a single object data table in object data format, with an additional first column indicating the source image.</p>"},{"location":"cli/export/#fcs","title":"FCS","text":"<p>To export specified object data from all images as a single .fcs file:</p> <pre><code>steinbock export fcs intensities regionprops -o objects.fcs\n</code></pre> <p>This will collect object data from the <code>intensities</code> and <code>regionprops</code> directories and create a single FCS file using the fcswrite package.</p>"},{"location":"cli/export/#anndata","title":"AnnData","text":"<p>To export specified object data to AnnData:</p> <pre><code>steinbock export anndata --intensities intensities --data regionprops --neighbors neighbors -o objects.h5ad\n</code></pre> <p>This will generate a single .h5ad file, with object intensities as main data, object regionprops as observation annotations, and neighbors as pairwise observation annotations (adjacency matrix in <code>adj</code>, distances in <code>dists</code>).</p> <p>AnnData file format</p> <p>To export the data as .loom or .zarr, specify <code>--format loom</code> or <code>--format zarr</code>, respectively.</p> <p>Currently, the .h5ad format does not allow for storing panel/image metadata, see issue #66.</p> <p>Multiple data sources</p> <p>The <code>--data</code> option can be specified multiple times to include different object data as observation annotationss.</p>"},{"location":"cli/export/#graphs","title":"Graphs","text":"<p>To export neighbors as spatial object graphs, with object data as node attributes:</p> <pre><code>steinbock export graphs --data intensities\n</code></pre> <p>By default, this will generate one .graphml file per graph using the networkx Python package, with object intensities as node attributes. The default destination directory is <code>graphs</code>.</p> <p>NetworkX file format</p> <p>To export the graphs as .gexf or .gml, specify <code>--format gexf</code> or <code>--format gml</code>, respectively.</p> <p>Multiple graph attributes sources</p> <p>The <code>--data</code> option can be specified multiple times to include different object data as graph attributes.</p>"},{"location":"cli/intro/","title":"Introduction","text":"<p>The following sections document the usage of the steinbock command-line interface (CLI).</p> <p>Prerequisites</p> <p>From this point onwards, it is assumed that the <code>steinbock</code> command alias was configured correctly. To make efficient use of the steinbock Docker container, basic command line skills are absolutely required. Furthermore, understanding key concepts of containerization using Docker may be helpful in resolving issues.</p>"},{"location":"cli/intro/#trying-it-out","title":"Trying it out","text":"<p>To try out steinbock, the IMC mock dataset can be used as follows:</p> <ol> <li>Copy the raw directory to your steinbock data/working directory</li> <li>Place the panel.csv into the <code>raw</code> directory in your steinbock data/working directory</li> <li>Continue with Imaging Mass Cytometry (IMC) preprocessing and subsequent steps</li> </ol> <p>Note</p> <p>Existing Ilastik training data (Ilastik pixel classification project, Ilastik crops) can be used for testing the classification step.</p>"},{"location":"cli/intro/#getting-help","title":"Getting help","text":"<p>At any time, use the <code>--help</code> option to show help about a steinbock command, e.g.:</p> <pre><code>&gt; steinbock --help\n\nUsage: steinbock [OPTIONS] COMMAND [ARGS]...\n\nOptions:\n--version  Show the version and exit.\n--help     Show this message and exit.\n\nCommands:\npreprocess  Extract and preprocess images from raw data\nclassify    Perform pixel classification to extract probabilities\nsegment     Perform image segmentation to create object masks\nmeasure     Extract object data from segmented images\nexport      Export data to third-party formats\nutils       Various utilities and tools\nview        View image using napari GUI\napps        Third-party applications\n</code></pre> <p>Directory structure</p> <p>Unless specified otherwise, all steinbock commands adhere to the default directory structure.</p> <p>For bug reports or further help, please do not hesitate to reach out via GitHub Issues/Discussions.</p>"},{"location":"cli/measurement/","title":"Object measurement","text":"<p>In this step, object-level (e.g. single-cell) data will be extracted from segmented images.</p> <p>Various types of data can be extracted, each of which is described in the following.</p> <p>Collecting multiple object data from multiple images</p> <p>To collect all object data (e.g. intensities, region properties) from all images into a single file, see Data export.</p>"},{"location":"cli/measurement/#object-intensities","title":"Object intensities","text":"<p>To extract mean object intensities per channel:</p> <pre><code>steinbock measure intensities\n</code></pre> <p>This will create object data tables in CSV format (see File types, one file per image). The default destination directory is <code>intensities</code>.</p> <p>Pixel aggregation</p> <p>By default, pixels belonging to an object are aggregated by taking the mean. To specify a different numpy function for aggregation, use the <code>--aggr</code> option (e.g. specify <code>--aggr median</code> to measure \"median object intensities\").</p>"},{"location":"cli/measurement/#region-properties","title":"Region properties","text":"<p>To extract spatial object properties (\"region properties\"):</p> <pre><code>steinbock measure regionprops\n</code></pre> <p>This will create object data tables in CSV format (see File types, one file per image). The default destination directory is <code>regionprops</code>.</p> <p>Region property selection</p> <p>By default, the following scikit-image region properties will be computed:</p> <ul> <li><code>area</code></li> <li><code>centroid</code></li> <li><code>major_axis_length</code></li> <li><code>minor_axis_length</code></li> <li><code>eccentricity</code></li> </ul> <p>An alternative selection of scikit-image region properties can be specified in the <code>regionprops</code> command, e.g.:</p> <pre><code>steinbock measure regionprops area convex_area perimeter\n</code></pre>"},{"location":"cli/measurement/#object-neighbors","title":"Object neighbors","text":"<p>Neighbors can be measured (i.e., identified) based on distances between object centroids or object borders, or by pixel expansion. For distance-based neighbor identification, the maximum distance and/or number of neighbors can be specified.</p> <p>Spatial object graphs</p> <p>Pairs of neighbors can be represented as edges on a spatial object graph, where each cell is a vertex (node), and neighboring cells are connected by an edge associated with a spatial distance.</p> <p>The following commands will create directed edge lists in CSV format (see File types, one file per image). For undirected graphs, i.e., graphs constructed by distance thresholding/pixel expansion, each edge will appear twice. The default destination directory is <code>neighbors</code>.</p>"},{"location":"cli/measurement/#centroid-distances","title":"Centroid distances","text":"<p>To find neighbors by thresholding on distances between object centroids:</p> <pre><code>steinbock measure neighbors --type centroids --dmax 15\n</code></pre> <p>To construct k-nearest neighbor (kNN) graphs based on object centroid distances:</p> <pre><code>steinbock measure neighbors --type centroids --kmax 5\n</code></pre> <p>Distance metric</p> <p>By default, the Euclidean distance distance is used. Other metrics can be specified using the <code>--metric</code> option, e.g.:</p> <pre><code>steinbock measure neighbors --type centroids --dmax 15 --metric cityblock\n</code></pre> <p>Available distance metrics are listed in the documentation for scipy.spatial.distance.pdist.</p> <p>Distance-thresholded kNN graphs</p> <p>The options <code>--dmax</code> and <code>--kmax</code> options can be combined to construct distance-thresholded kNN graphs, e.g.:</p> <pre><code>steinbock measure neighbors --type centroids --dmax 15 --kmax 5\n</code></pre>"},{"location":"cli/measurement/#border-distances","title":"Border distances","text":"<p>To find neighbors by thresholding on Euclidean distances between object borders:</p> <pre><code>steinbock measure neighbors --type borders --dmax 4\n</code></pre> <p>To construct k-nearest neighbor (kNN) graphs based on Euclidean object border distances:</p> <pre><code>steinbock measure neighbors --type borders --kmax 5 --dmax 20\n</code></pre> <p>Computational complexity</p> <p>The construction of spatial kNN graphs based on Euclidean distances between object borders is computationally expensive. To speed up the computation, always specify a suitable <code>--dmax</code> value like in the example above.</p>"},{"location":"cli/measurement/#pixel-expansion","title":"Pixel expansion","text":"<p>To find neighbors by Euclidean pixel expansion (morphological dilation):</p> <pre><code>steinbock measure neighbors --type expansion --dmax 4\n</code></pre> <p>Pixel expansion versus border distances</p> <p>Neighbor identification by pixel expansion is a special case of finding neighbors based on Euclidean distances between object borders, in which, after pixel expansion, only touching objects (i.e., objects within a 4-neighborhood) are considered neighbors.</p>"},{"location":"cli/measurement/#cellprofiler-legacy","title":"CellProfiler (legacy)","text":"<p>Legacy operation</p> <p>The output of this operation is not actively supported by downstream processing steps.</p>"},{"location":"cli/measurement/#pipeline-preparation","title":"Pipeline preparation","text":"<p>To prepare a CellProfiler measurement pipeline:</p> <pre><code>steinbock measure cellprofiler prepare\n</code></pre> <p>Data/working directory</p> <p>Within the container, your data/working directory containing the CellProfiler pipeline is accessible under <code>/data</code>.</p> <p>By default, this will create a CellProfiler pipeline file <code>cell_measurement.cppipe</code> and collect all images and masks (both in 16-bit unsigned integer format) into the <code>cellprofiler_input</code> directory.</p> <p>CellProfiler plugins</p> <p>The generated CellProfiler pipeline makes use of custom plugins for multi-channel images, which are pre-installed in the steinbock Docker container. It can be inspected using CellProfiler as described in the following section.</p>"},{"location":"cli/measurement/#modifying-the-pipeline","title":"Modifying the pipeline","text":"<p>To interactively inspect, modify and run the pipeline, import it in CellProfiler (see Apps):</p> <pre><code>steinbock apps cellprofiler\n</code></pre> <p>More detailed instructions on how to create CellProfiler pipelines can be found here.</p>"},{"location":"cli/measurement/#batch-processing","title":"Batch processing","text":"<p>After the pipeline has been configured, it can be applied to a batch of images and masks:</p> <pre><code>steinbock measure cellprofiler run\n</code></pre> <p>By default, this will generate (undocumented and unstandardized) CellProfiler output as configured in the pipeline and store it in the <code>cellprofiler_output</code> directory.</p>"},{"location":"cli/preprocessing/","title":"Preprocessing","text":"<p>In this step, image data will be prepared for processing with steinbock.</p> <p>Various sources for raw data are supported by steinbock, each of which is described in the following. If you miss support for an imaging modality, please consider filing an issue on GitHub.</p> <p>Optional preprocessing</p> <p>The steinbock toolkit natively supports input images saved in Tag Image File Format (TIFF), see File types. If you already have preprocessed TIFF files, you can directly use those for further processing. If you have preprocessed images in another file format supported by imageio, you need to convert them to steinbock-compatible TIFF files first, see External images.</p> <p>Computational resources</p> <p>Unless specified otherwise, steinbock converts all input images to 32-bit floating point images upon loading, see File types. For large images, this may exhaust a system's available random access memory (RAM). In these situations, it is recommended to run all operations on image tiles instead, see mosaics.</p>"},{"location":"cli/preprocessing/#imaging-mass-cytometry-imc","title":"Imaging mass cytometry (IMC)","text":"<p>Preprocessing of IMC data consists of two steps:</p> <ol> <li>Create a steinbock panel file and, optionally, edit it to select channels</li> <li>Extract images from .mcd/.txt files according to the created steinbock panel file</li> </ol> <p>Panel-based image extraction</p> <p>The steinbock panel determines the presence and order of channels in the extracted images.</p>"},{"location":"cli/preprocessing/#panel-creation","title":"Panel creation","text":"<p>A steinbock panel file contains information about the channels in an image, such as channel ID (e.g. metal tag), channel name (e.g. antibody target), or whether a channel will be used in certain tasks (e.g. classification, segmentation). Multiple options exist for creating a steinbock panel file for IMC applications:</p> <ul> <li>Manual steinbock panel file creation, following the steinbock panel format specification</li> <li>Automatic steinbock panel file creation from metadata embedded in raw MCD/TXT files</li> <li>Conversion from an \"IMC panel file\" in IMC Segmentation Pipeline<sup>1</sup> format (undocumented)</li> </ul> <p>Panel file types</p> <p>The steinbock panel file is different from the \"IMC panel file\" used in the original IMC Segmentation Pipeline<sup>1</sup> in that it is ordered (i.e., the channel order in the panel matches the channel order in the images) and only requires <code>channel</code> and <code>name</code> columns (see File types). By default, channels in a steinbock panel file generated from IMC raw data are sorted by mass. As the steinbock panel format allows for further arbitrary columns, unmapped columns from an original \"IMC panel\" will be \"passed through\" to the generated steinbock panel.</p> <p>When manually creating the steinbock panel file, no further actions are required; proceed with image conversion. Otherwise, to create a steinbock panel file for IMC data processing:</p> <pre><code>steinbock preprocess imc panel\n</code></pre> <p>This will create a steinbock panel at the specified location (defaults to <code>panel.csv</code>) as follows:</p> <ul> <li>If an IMC panel file (in IMC Segmentation Pipeline<sup>1</sup> format, undocumented) exists at the specified location (defaults to <code>raw/panel.csv</code>), it is converted to the steinbock panel format.</li> <li>If no IMC panel file was found, the steinbock panel is created based on all acquisitions in all .mcd files found at the specified location (defaults to <code>raw</code>).</li> <li>If no IMC panel file and no .mcd file were found, the steinbock panel is created based on all .txt files found at the specified location (defaults to <code>raw</code>).</li> </ul> <p>Different panels</p> <p>In principle, IMC supports acquiring a different panel for each .mcd/.txt file and acquisition. When creating a steinbock panel from .mcd/.txt files, the created panel will contain all targets found in any of the input files. During image conversion (see below), only targets marked as <code>keep=1</code> in the panel file will be retained; imaging data with missing channels (identified by the <code>channel</code> column in the panel file) are skipped.</p>"},{"location":"cli/preprocessing/#image-conversion","title":"Image conversion","text":"<p>To convert .mcd/.txt files in the raw data directory to TIFF and filter hot pixels:</p> <pre><code>steinbock preprocess imc images --hpf 50\n</code></pre> <p>This will extract images from raw files (source directory defaults to <code>raw</code>) and save them at the specified location (defaults to <code>img</code>). Each image corresponds to one acquisition in one file, with the image channels filtered (<code>keep</code> column) and sorted according to the steinbock panel file at the specified location (defaults to <code>panel.csv</code>). For corrupted .mcd files, steinbock will try to recover the missing acquisitions from matching .txt files. In a second step, images from unmatched .txt files are extracted as well.</p> <p>Furthermore, this commands also creates an image information table as described in File types. In addition to the default columns, the following IMC-specific columns will be added:</p> <ul> <li><code>source_file</code>: the raw .mcd/.txt file name</li> <li><code>recovery_file</code>: the corresponding .txt file name, if available</li> <li><code>recovered</code>: True if the .mcd acquisition was recovered from the corresponding .txt file</li> <li>Acquisition-specific information (only for images extracted from .mcd files):<ul> <li><code>acquisition_id</code>: numeric acquisition ID</li> <li><code>acquisition_description</code>: user-specified acquisition description</li> <li><code>acquisition_posx_um</code>, <code>acquisition_posy_um</code>: start position, in micrometers</li> <li><code>acquisition_width_um</code>, <code>acquisition_height_um</code>: dimensions, in micrometers</li> </ul> </li> </ul> <p>IMC file matching</p> <p>Matching of .txt files to .mcd files is performed by file name: If a .txt file name starts with the file name of an .mcd file (without extension) AND ends with <code>_{acquisition}.txt</code>, where <code>{acquisition}</code> is the numeric acquisition ID, it is considered matching that particular acquisition from the .mcd file.</p> <p>ZIP archives</p> <p>If .zip archives are found in the raw data directory, contained .txt/.mcd files will be automatically extracted to a temporary directory, unless disabled using the <code>--no-unzip</code> command-line option. After image extraction, this temporary directory and its contents will be removed.</p> <p>After image extraction, if the <code>--hpf</code> option is specified, the images are filtered for hot pixels. The value of the <code>--hpf</code> option (<code>50</code> in the example above) determines the hot pixel filtering threshold.</p> <p>Hot pixel filtering</p> <p>Hot pixel filtering works by comparing each pixel to its 8-neighborhood (i.e., neighboring pixels at a Chebyshev distance of 1). If the difference (not: absolute difference) between the pixel and any of its 8 neighbor pixels exceeds a hot pixel filtering threshold, the pixel is set to the maximum neighbor pixel value (\"hot pixel-filtered\"). In the original implementation of the IMC Segmentation Pipeline<sup>1</sup>, a hot pixel filtering threshold of 50 is recommended.</p>"},{"location":"cli/preprocessing/#external-images","title":"External images","text":"<p>External images are images preprocessed externally (i.e., without steinbock) that are saved in an image format supported by imageio.</p> <p>For convenience, to create a template panel file based on external image data stored at the specified location (defaults to <code>external</code>):</p> <pre><code>steinbock preprocess external panel\n</code></pre> <p>To convert external image data to steinbock-supported TIFF files (see File types) and save them to the specified location (defaults to <code>external</code>):</p> <pre><code>steinbock preprocess external images\n</code></pre> <ol> <li> <p>Zanotelli et al. ImcSegmentationPipeline: A pixel classification-based multiplexed image segmentation pipeline. Zenodo, 2017. DOI: 10.5281/zenodo.3841961.\u00a0\u21a9\u21a9\u21a9\u21a9</p> </li> </ol>"},{"location":"cli/segmentation/","title":"Object segmentation","text":"<p>In this step, objects such as cells will be segmented. This will result in grayscale object masks of the same x and y dimensions as the original images, containing unique pixel values for each object (object IDs, see File types).</p> <p>Various segmentation approaches are supported, each of which is described in the following.</p> <p>Pixel classification-based image segmentation vs end-to-end approaches</p> <p>While pixel classification-based image segmentation using CellProfiler uses probability images to segment objects, end-to-end workflows such as DeepCell/Mesmer and Cellpose directly operate on images without the need for a preceding pixel classification step.</p>"},{"location":"cli/segmentation/#cellprofiler","title":"CellProfiler","text":"<p>CellProfiler is an open-source software for measuring and analyzing cell images. Here, CellProfiler is used for object detection and region growth-based object segmentation.</p> <p>Pixel classification-based image segmentation</p> <p>By design, the segmentation approach described in this section will be used as part of a pixel classification-based image segmentation workflow. As such, this approach requires probability images generated by a preceding pixel classification step as input; the assigned class probabilities will be used to identify and segment objects.</p>"},{"location":"cli/segmentation/#pipeline-preparation","title":"Pipeline preparation","text":"<p>In a first step, a CellProfiler pipeline is prepared for processing the images:</p> <pre><code>steinbock segment cellprofiler prepare\n</code></pre> <p>By default, this will create a CellProfiler pipeline <code>cell_segmentation.cppipe</code> for segmenting cells in probability images generated during the Ilastik pixel classification step.</p> <p>CellProfiler plugins</p> <p>The generated CellProfiler pipeline makes use of custom plugins for multi-channel images, which are pre-installed in the steinbock Docker container. The pipeline can be inspected using CellProfiler as described below.</p>"},{"location":"cli/segmentation/#modifying-the-pipeline","title":"Modifying the pipeline","text":"<p>To interactively inspect, modify and run the pipeline, import it in CellProfiler (see Apps):</p> <pre><code>steinbock apps cellprofiler\n</code></pre> <p>Data/working directory</p> <p>Within the container, your data/working directory containing the CellProfiler pipeline is accessible under <code>/data</code>.</p> <p>More detailed instructions on how to create CellProfiler pipelines can be found here.</p> <p>Segmentation parameters</p> <p>Segmentation using CellProfiler is highly customizable and sensitive to parameter choices. The default parameter values may not be suitable in all cases and parameter values require careful tuning for each dataset.</p> <p>In particular, the generated pipeline is configured to down-size the probability images by a factor of two, to account for the default scaling applied in the Ilastik pixel classification step. If a different classification strategy or scale factor has been used to generate the probability images, the down-scale factor must be adjusted accordingly.</p> <p>CellProfiler output</p> <p>By default, the pipeline is configured to generate object masks as grayscale 16-bit unsigned integer TIFF images with the same name and x and y dimensions as the input images (see File types). Custom segmentation pipelines should adhere to this convention to ensure compatibility with downstream measurement tasks.</p>"},{"location":"cli/segmentation/#batch-processing","title":"Batch processing","text":"<p>After the pipeline has been configured, it can be applied to a batch of probability images:</p> <pre><code>steinbock segment cellprofiler run\n</code></pre> <p>This will create grayscale object masks of the same x and y dimensions as the original images, containing unique pixel values for each object (object IDs, see File types). The default destination directory for these masks is <code>masks</code>.</p>"},{"location":"cli/segmentation/#deepcell","title":"DeepCell","text":"<p>DeepCell is a deep learning library for single-cell analysis of biological images. Here, pre-trained DeepCell models are used for cell/nuclei segmentation from raw image data.</p> <p>End-to-end cell segmentation</p> <p>This approach operates directly on image intensities and does not require a preceding pixel classification step.</p> <p>To segment cells using Mesmer:</p> <pre><code>steinbock segment deepcell --minmax\n</code></pre> <p>To segment nuclei using Mesmer:</p> <pre><code>steinbock segment deepcell --minmax --type nuclear\n</code></pre> <p>This will create grayscale cell/nuclear masks of the same x and y dimensions as the original images, containing unique pixel values for each cell/nucleus (object IDs, see File types). The default destination directory for these masks is <code>masks</code>.</p> <p>Pre-trained models</p> <p>DeepCell uses pre-trained neural networks for object segmentation. To specify a pre-trained model, use the <code>--model</code> option. If not specified, the default training data for the selected application (e.g. Mesmer) is downloaded.</p> <p>DeepCell image data</p> <p>Depending on the application, DeepCell requires images of specific dimensions. For example, in the case of cell segmentation using Mesmer, DeepCell expects two-channel images as input, where the first channel must be a nuclear channel (e.g. DAPI) and the second channel must be a membrane or cytoplasmic channel (e.g. E-Cadherin). This also applies to <code>nuclear</code>-only segmentation tasks.</p> <p>If a <code>deepcell</code> column is present in the steinbock panel file, channels are sorted and grouped according to values in that column to generate the required input for DeepCell: For each image, each group of channels is aggregated by computing the mean along the channel axis (use the <code>--aggr</code> option to specify a different aggregation strategy). The resulting images consist of one channel per group; channels without a group label are ignored.</p> <p>If no <code>deepcell</code> column is present, images are expected to be in the correct format already.</p> <p>Unless specified otherwise using the <code>--pixelsize</code> parameter, a value of 1 micrometer per pixel is assumed. This resolution parameter can also be used to fine-tune the generated cell/nuclear masks with regards to over/under-segmentation.</p> <p>Channel-wise image normalization</p> <p>If enabled, features (i.e., channels) are scaled for each image and each channel independently.</p> <p>Specify <code>--minmax</code> to enable min-max normalization and <code>--zscore</code> to enable z-score normalization.</p> <p>Preprocessing/postprocessing parameters</p> <p>Application-dependent preprocessing/postprocessing parameters can be specified in YAML files using the <code>--preprocess</code>/<code>--postprocess</code> options. For the Mesmer application, this can e.g. be used to control thresholding, histogram normalization and watershed segmentation. Please refer to the DeepCell online documentation for available parameters. For example, one could specify <code>--preprocess preprocessing.yml</code>, where <code>preprocessing.yml</code> is a file in the steinbock data/working directory containing:</p> <pre><code>threshold: true\npercentile: 99.9\nnormalize: true\nkernel_size: 128\n</code></pre>"},{"location":"cli/segmentation/#cellpose","title":"Cellpose","text":"<p>Experimental feature</p> <p>This is an experimental feature and is only available in the <code>-cellpose</code> flavors of the steinbock Docker container.</p> <p>Segmentation using cellpose likely requires fine-tuning of parameters, e.g. using steinbock command-line interface options.</p> <p>Cellpose is a generalist algorithm for cellular segmentation.</p> <p>End-to-end cell segmentation</p> <p>This approach operates directly on image intensities and does not require a preceding pixel classification step.</p> <p>To segment cells using the default <code>cyto2</code> model:</p> <pre><code>steinbock segment cellpose --minmax\n</code></pre> <p>To segment nuclei using the <code>nuclei</code> model:</p> <pre><code>steinbock segment cellpose --minmax --model nuclei\n</code></pre> <p>Cellpose image data</p> <p>Cellpose expects two-channel images as input, where the first channel must be a nuclear channel (e.g. DAPI) and the second channel must be a cytoplasmic channel (e.g. E-Cadherin). The nuclear channel is optional and only the cytoplasmic channel (\"channel to segment\") is required. Note that - compared to the original cellpose implementation - the channel order is reversed for compatibility with DeepCell/Mesmer.</p> <p>If a <code>cellpose</code> column is present in the steinbock panel file, channels are sorted and grouped according to values in that column to generate the required input for DeepCell: For each image, each group of channels is aggregated by computing the mean along the channel axis (use the <code>--aggr</code> option to specify a different aggregation strategy). The resulting images consist of one channel per group; channels without a group label are ignored.</p> <p>If no <code>cellpose</code> column is present, images are expected to be in the correct format already.</p> <p>GPU support</p> <p>Currently. steinbock does not support cellpose segmentation with GPU support.</p> <p>If GPU support is required, consider running cellpose on your host system independently.</p>"},{"location":"cli/utils/","title":"Utilities","text":"<p>Various built-in utilities are exposed via steinbock's <code>utils</code> command.</p>"},{"location":"cli/utils/#matching","title":"Matching","text":"<p>The following command will, for each pair of masks, identify overlapping (intersecting) objects:</p> <pre><code>steinbock utils match cell_masks tumor_masks -o matched_objects\n</code></pre> <p>Here, <code>cell_masks</code> and <code>tumor_masks</code> are path to directories containing masks. Masks from both directories are matched by name. This will generate tables in CSV format (undocumented, one file per mask pair), with each row indicating IDs from overlapping objects in both masks.</p> <p>Usage example</p> <p>Identifying overlapping objects can be useful in multi-segmentation contexts. For example, one may be interested in cells from tumor regions only, in which case two segmentation workflows would be followed sequentially:</p> <ul> <li>\"Global\" tumor/stroma segmentation</li> <li>\"Local\" cell segmentation</li> </ul> <p>Afterwards, one could match the generated masks to restrict downstream analyses to cells in tumor regions.</p>"},{"location":"cli/utils/#mosaics","title":"Mosaics","text":"<p>This steinbock utility for tiling and stitching images allows the processing of large image files.</p> <p>Data type</p> <p>Unlike other steinbock operations, all <code>mosaic</code> commands load and save images in their original data type.</p>"},{"location":"cli/utils/#tiling-images","title":"Tiling images","text":"<p>The following command will split all images in <code>img_full</code> into tiles of 4096x4096 pixels (the recommended maximum image size for steinbock on local installations) and save them to <code>img</code>:</p> <pre><code>steinbock utils mosaics tile img_full --size 4096 -o img\n</code></pre> <p>The created image tiles will have the following file name, where <code>{IMG}</code> is the original file name (without extension), <code>{X}</code> and <code>{Y}</code> indicate the tile position (in pixels) and <code>{W}</code> and <code>{H}</code> indicate the tile width and height, respectively:</p> <pre><code>{IMG}_tx{X}_ty{Y}_tw{W}_th{H}.tiff\n</code></pre>"},{"location":"cli/utils/#stitching-mosaics","title":"Stitching mosaics","text":"<p>The following command will stitch all mask tiles in <code>masks</code> (following the file conventions above) to assemble masks of original size and save them to <code>masks_full</code>:</p> <pre><code>steinbock utils mosaics stitch masks -o masks_full\n</code></pre>"},{"location":"cli/visualization/","title":"Visualization","text":""},{"location":"cli/visualization/#images","title":"Images","text":"<p>In this step, images and masks are visualized using the napari image viewer.</p> <p>Experimental feature</p> <p>This is a highly experimental feature. It requires OpenGL-enabled X forwarding and will not work on most systems. Alternatively, one can resort to Xpra-enabled Docker containers to run a steinbock-enabled desktop environment within a web browser (undocumented).</p> <p>Docker and graphical user interfaces</p> <p>Running napari using steinbock Docker containers requires support for graphical user interfaces (e.g. X forwarding).</p> <p>To open the image <code>myimage.tiff</code> (and, optionally, the corresponding mask) in napari:</p> <pre><code>steinbock view myimage.tiff\n</code></pre>"},{"location":"python/intro/","title":"Introduction","text":"<p>The steinbock toolkit can be used as a regular Python package:</p> <pre><code>import steinbock\n</code></pre> <p>Please refer to the steinbock API documentation for further details.</p> <p>Usage examples can be found in the examples folder on GitHub.</p> <p>Work in progress</p> <p>The steinbock API documentation is work in progress.</p>"},{"location":"python/api/steinbock.classification/","title":"steinbock.classification","text":""},{"location":"python/api/steinbock.classification/#steinbock.classification.ilastik","title":"<code>ilastik</code>  <code>special</code>","text":""},{"location":"python/api/steinbock.classification/#steinbock.classification.ilastik.data","title":"<code>data</code>  <code>special</code>","text":""},{"location":"python/api/steinbock.export/","title":"steinbock.export","text":""},{"location":"python/api/steinbock.export/#steinbock.export.data","title":"<code>data</code>","text":""},{"location":"python/api/steinbock.export/#steinbock.export.data.logger","title":"<code>logger</code>","text":""},{"location":"python/api/steinbock.export/#steinbock.export.data.try_convert_to_anndata_from_disk","title":"<code>try_convert_to_anndata_from_disk(intensity_files, *data_file_lists, *, neighbors_files=None, panel=None, image_info=None)</code>","text":"Source code in <code>steinbock/export/data.py</code> <pre><code>def try_convert_to_anndata_from_disk(\n    intensity_files: Sequence[Union[str, PathLike]],\n    *data_file_lists,\n    neighbors_files: Optional[Sequence[Union[str, PathLike]]] = None,\n    panel: Optional[pd.DataFrame] = None,\n    image_info: Optional[pd.DataFrame] = None,\n) -&gt; Generator[Tuple[str, Path, Tuple[Path, ...], Optional[Path], AnnData], None, None]:\n    if panel is not None:\n        panel = panel.set_index(\"name\", drop=False, verify_integrity=True)\n    if image_info is not None:\n        image_info = image_info.set_index(\"image\", drop=False, verify_integrity=True)\n    for i, intensity_file in enumerate(intensity_files):\n        intensity_file = Path(intensity_file)\n        data_files = tuple(Path(dfl[i]) for dfl in data_file_lists)\n        neighbors_file = None\n        if neighbors_files is not None:\n            neighbors_file = Path(neighbors_files[i])\n        img_file_name = io._as_path_with_suffix(intensity_file, \".tiff\").name\n        try:\n            x = io.read_data(intensity_file)\n            obs = None\n            if len(data_files) &gt; 0:\n                obs = io.read_data(data_files[0])\n                for data_file in data_files[1:]:\n                    obs = pd.merge(\n                        obs,\n                        io.read_data(data_file),\n                        left_index=True,\n                        right_index=True,\n                    )\n                obs = obs.loc[x.index, :]\n            if image_info is not None:\n                image_obs = (\n                    pd.concat([image_info.loc[img_file_name, :]] * len(x.index), axis=1)\n                    .transpose()\n                    .astype(image_info.dtypes.to_dict())\n                )\n                image_obs.index = x.index\n                image_obs.columns = \"image_\" + image_obs.columns\n                image_obs.rename(columns={\"image_image\": \"image\"}, inplace=True)\n                if obs is not None:\n                    obs = pd.merge(\n                        obs,\n                        image_obs,\n                        how=\"inner\",  # preserves order of left keys\n                        left_index=True,\n                        right_index=True,\n                    )\n                else:\n                    obs = image_obs\n            var = None\n            if panel is not None:\n                var = panel.loc[x.columns, :].copy()\n            if obs is not None:\n                obs.index = [f\"Object {object_id}\" for object_id in x.index]\n            if var is not None:\n                var.index = x.columns.astype(str).tolist()\n            # convert nullable string dtype to generic object dtype\n            # https://github.com/BodenmillerGroup/steinbock/issues/66\n            if obs is not None:\n                for col, dtype in zip(obs.columns, obs.dtypes):\n                    if dtype == \"string\":\n                        obs[col] = obs[col].astype(str)\n            if var is not None:\n                for col, dtype in zip(var.columns, var.dtypes):\n                    if dtype == \"string\":\n                        var[col] = var[col].astype(str)\n            adata = AnnData(X=x.values, obs=obs, var=var, dtype=np.float32)\n            if neighbors_file is not None:\n                neighbors = io.read_neighbors(neighbors_file)\n                row_ind = [x.index.get_loc(a) for a in neighbors[\"Object\"]]\n                col_ind = [x.index.get_loc(b) for b in neighbors[\"Neighbor\"]]\n                adata.obsp[\"adj\"] = csr_matrix(\n                    ([True] * len(neighbors.index), (row_ind, col_ind)),\n                    shape=(adata.n_obs, adata.n_obs),\n                    dtype=np.uint8,\n                )\n                if neighbors[\"Distance\"].notna().any():\n                    adata.obsp[\"dist\"] = csr_matrix(\n                        (neighbors[\"Distance\"].values, (row_ind, col_ind)),\n                        shape=(adata.n_obs, adata.n_obs),\n                        dtype=np.float32,\n                    )\n                del neighbors\n            yield (\n                img_file_name,\n                intensity_file,\n                data_files,\n                neighbors_file,\n                adata,\n            )\n            del x, obs, var, adata\n        except Exception as e:\n            logger.exception(\n                f\"Error creating AnnData object for image {img_file_name}: {e}; \"\n                \"skipping image\"\n            )\n</code></pre>"},{"location":"python/api/steinbock.export/#steinbock.export.data.try_convert_to_dataframe_from_disk","title":"<code>try_convert_to_dataframe_from_disk(*data_file_lists)</code>","text":"Source code in <code>steinbock/export/data.py</code> <pre><code>def try_convert_to_dataframe_from_disk(\n    *data_file_lists,\n) -&gt; Generator[Tuple[str, Tuple[Path, ...], pd.DataFrame], None, None]:\n    for data_files in zip(*data_file_lists):\n        data_files = tuple(Path(data_file) for data_file in data_files)\n        img_file_name = io._as_path_with_suffix(data_files[0], \".tiff\").name\n        try:\n            df = io.read_data(data_files[0])\n            for data_file in data_files[1:]:\n                df = pd.merge(\n                    df,\n                    io.read_data(data_file),\n                    left_index=True,\n                    right_index=True,\n                )\n            yield img_file_name, data_files, df\n            del df\n        except Exception as e:\n            logger.exception(\n                f\"Error creating DataFrame for image {img_file_name}: {e}; \"\n                \"skipping image\"\n            )\n</code></pre>"},{"location":"python/api/steinbock.export/#steinbock.export.graphs","title":"<code>graphs</code>","text":""},{"location":"python/api/steinbock.export/#steinbock.export.graphs.logger","title":"<code>logger</code>","text":""},{"location":"python/api/steinbock.export/#steinbock.export.graphs.convert_to_networkx","title":"<code>convert_to_networkx(neighbors, *data_list)</code>","text":"Source code in <code>steinbock/export/graphs.py</code> <pre><code>def convert_to_networkx(neighbors: pd.DataFrame, *data_list) -&gt; nx.Graph:\n    edges = neighbors[[\"Object\", \"Neighbor\"]].astype(int).values.tolist()\n    undirected_edges = [tuple(sorted(edge)) for edge in edges]\n    is_directed = any([x != 2 for x in Counter(undirected_edges).values()])\n    graph: nx.Graph = nx.from_pandas_edgelist(\n        neighbors,\n        source=\"Object\",\n        target=\"Neighbor\",\n        edge_attr=True,\n        create_using=nx.DiGraph if is_directed else nx.Graph,\n    )\n    if len(data_list) &gt; 0:\n        merged_data = data_list[0]\n        for data in data_list[1:]:\n            merged_data = pd.merge(merged_data, data, left_index=True, right_index=True)\n        node_attributes = {\n            int(object_id): object_data.to_dict()\n            for object_id, object_data in merged_data.iterrows()\n        }\n        nx.set_node_attributes(graph, node_attributes)\n    return graph\n</code></pre>"},{"location":"python/api/steinbock.export/#steinbock.export.graphs.try_convert_to_networkx_from_disk","title":"<code>try_convert_to_networkx_from_disk(neighbors_files, *data_file_lists)</code>","text":"Source code in <code>steinbock/export/graphs.py</code> <pre><code>def try_convert_to_networkx_from_disk(\n    neighbors_files: Sequence[Union[str, PathLike]], *data_file_lists\n) -&gt; Generator[Tuple[Path, Tuple[Path, ...], nx.Graph], None, None]:\n    for neighbors_file, *data_files in zip(neighbors_files, *data_file_lists):\n        data_files = tuple(Path(data_file) for data_file in data_files)\n        try:\n            neighbors = io.read_neighbors(neighbors_file)\n            data_list = [io.read_data(data_file) for data_file in data_files]\n            graph = convert_to_networkx(neighbors, *data_list)\n            yield Path(neighbors_file), data_files, graph\n            del neighbors, data_list, graph\n        except Exception as e:\n            logger.exception(f\"Error converting {neighbors_file} to networkx: {e}\")\n</code></pre>"},{"location":"python/api/steinbock.io/","title":"steinbock.io","text":""},{"location":"python/api/steinbock.io/#steinbock.io.img_dtype","title":"<code>img_dtype</code>","text":""},{"location":"python/api/steinbock.io/#steinbock.io.logger","title":"<code>logger</code>","text":""},{"location":"python/api/steinbock.io/#steinbock.io.mask_dtype","title":"<code>mask_dtype</code>","text":""},{"location":"python/api/steinbock.io/#steinbock.io.SteinbockIOException","title":"<code> SteinbockIOException            (SteinbockException)         </code>","text":"Source code in <code>steinbock/io.py</code> <pre><code>class SteinbockIOException(SteinbockException):\n    pass\n</code></pre>"},{"location":"python/api/steinbock.io/#steinbock.io.list_data_files","title":"<code>list_data_files(data_dir, base_files=None)</code>","text":"Source code in <code>steinbock/io.py</code> <pre><code>def list_data_files(\n    data_dir: Union[str, PathLike],\n    base_files: Optional[Sequence[Union[str, PathLike]]] = None,\n) -&gt; List[Path]:\n    if base_files is not None:\n        return _list_related_files(base_files, data_dir, \".csv\")\n    return sorted(Path(data_dir).rglob(\"[!.]*.csv\"))\n</code></pre>"},{"location":"python/api/steinbock.io/#steinbock.io.list_image_files","title":"<code>list_image_files(img_dir, base_files=None)</code>","text":"Source code in <code>steinbock/io.py</code> <pre><code>def list_image_files(\n    img_dir: Union[str, PathLike],\n    base_files: Optional[Sequence[Union[str, PathLike]]] = None,\n) -&gt; List[Path]:\n    if base_files is not None:\n        return _list_related_files(base_files, img_dir, \".tiff\")\n    return sorted(Path(img_dir).rglob(\"[!.]*.tiff\"))\n</code></pre>"},{"location":"python/api/steinbock.io/#steinbock.io.list_mask_files","title":"<code>list_mask_files(mask_dir, base_files=None)</code>","text":"Source code in <code>steinbock/io.py</code> <pre><code>def list_mask_files(\n    mask_dir: Union[str, PathLike],\n    base_files: Optional[Sequence[Union[str, PathLike]]] = None,\n) -&gt; List[Path]:\n    if base_files is not None:\n        return _list_related_files(base_files, mask_dir, \".tiff\")\n    return sorted(Path(mask_dir).rglob(\"[!.]*.tiff\"))\n</code></pre>"},{"location":"python/api/steinbock.io/#steinbock.io.list_neighbors_files","title":"<code>list_neighbors_files(neighbors_dir, base_files=None)</code>","text":"Source code in <code>steinbock/io.py</code> <pre><code>def list_neighbors_files(\n    neighbors_dir: Union[str, PathLike],\n    base_files: Optional[Sequence[Union[str, PathLike]]] = None,\n) -&gt; List[Path]:\n    if base_files is not None:\n        return _list_related_files(base_files, neighbors_dir, \".csv\")\n    return sorted(Path(neighbors_dir).rglob(\"[!.]*.csv\"))\n</code></pre>"},{"location":"python/api/steinbock.io/#steinbock.io.mmap_image","title":"<code>mmap_image(img_file, mode='r', **kwargs)</code>","text":"Source code in <code>steinbock/io.py</code> <pre><code>def mmap_image(img_file: Union[str, PathLike], mode=\"r\", **kwargs) -&gt; np.ndarray:\n    if \"imagej\" not in kwargs and mode == \"r+\":\n        kwargs[\"imagej\"] = True\n    img_exists = Path(img_file).is_file()\n    img = tifffile.memmap(img_file, mode=mode, **kwargs)\n    if img_exists:\n        if img.dtype != img_dtype:\n            logger.warning(\n                \"Data type of memory-mapped image file %s (%s) is not %s\",\n                img_file,\n                img.dtype,\n                img_dtype,\n            )\n        img = _fix_image_shape(img_file, img)\n    return img\n</code></pre>"},{"location":"python/api/steinbock.io/#steinbock.io.mmap_mask","title":"<code>mmap_mask(mask_file, mode='r', **kwargs)</code>","text":"Source code in <code>steinbock/io.py</code> <pre><code>def mmap_mask(mask_file: Union[str, PathLike], mode=\"r\", **kwargs) -&gt; np.ndarray:\n    if \"imagej\" not in kwargs and mode == \"r+\":\n        kwargs[\"imagej\"] = True\n    mask_exists = Path(mask_file).is_file()\n    mask = tifffile.memmap(mask_file, mode=mode, **kwargs)\n    if mask_exists:\n        if mask.dtype != mask_dtype:\n            logger.warning(\n                \"Data type of memory-mapped mask file %s (%s) is not %s\",\n                mask_file,\n                mask.dtype,\n                mask_dtype,\n            )\n        mask = _fix_mask_shape(mask_file, mask)\n    return mask\n</code></pre>"},{"location":"python/api/steinbock.io/#steinbock.io.read_data","title":"<code>read_data(data_file)</code>","text":"Source code in <code>steinbock/io.py</code> <pre><code>def read_data(data_file: Union[str, PathLike]) -&gt; pd.DataFrame:\n    return pd.read_csv(data_file, sep=\",|;\", index_col=\"Object\", engine=\"python\")\n</code></pre>"},{"location":"python/api/steinbock.io/#steinbock.io.read_image","title":"<code>read_image(img_file, native_dtype=False)</code>","text":"Source code in <code>steinbock/io.py</code> <pre><code>def read_image(\n    img_file: Union[str, PathLike],\n    native_dtype: bool = False,\n) -&gt; np.ndarray:\n    img = tifffile.imread(img_file, squeeze=False)\n    img = _fix_image_shape(img_file, img)\n    if not native_dtype:\n        img = _to_dtype(img, img_dtype)\n    return img\n</code></pre>"},{"location":"python/api/steinbock.io/#steinbock.io.read_image_info","title":"<code>read_image_info(image_info_file)</code>","text":"Source code in <code>steinbock/io.py</code> <pre><code>def read_image_info(image_info_file: Union[str, PathLike]) -&gt; pd.DataFrame:\n    image_info = pd.read_csv(\n        image_info_file,\n        sep=\",|;\",\n        dtype={\n            \"image\": pd.StringDtype(),\n            \"width_px\": pd.UInt16Dtype(),\n            \"height_px\": pd.UInt16Dtype(),\n            \"num_channels\": pd.UInt8Dtype(),\n        },\n        engine=\"python\",\n    )\n    for required_col in (\"image\", \"width_px\", \"height_px\", \"num_channels\"):\n        if required_col not in image_info:\n            raise SteinbockIOException(\n                f\"Missing '{required_col}' column in {image_info_file}\"\n            )\n    for notnan_col in (\"image\", \"width_px\", \"height_px\", \"num_channels\"):\n        if notnan_col in image_info and image_info[notnan_col].isna().any():\n            raise SteinbockIOException(\n                f\"Missing values for '{notnan_col}' in {image_info_file}\"\n            )\n    for unique_col in (\"image\",):\n        if unique_col in image_info:\n            if image_info[unique_col].dropna().duplicated().any():\n                raise SteinbockIOException(\n                    f\"Duplicated values for '{unique_col}'\" f\" in {image_info_file}\"\n                )\n    return image_info\n</code></pre>"},{"location":"python/api/steinbock.io/#steinbock.io.read_mask","title":"<code>read_mask(mask_file, native_dtype=False)</code>","text":"Source code in <code>steinbock/io.py</code> <pre><code>def read_mask(\n    mask_file: Union[str, PathLike],\n    native_dtype: bool = False,\n) -&gt; np.ndarray:\n    mask = tifffile.imread(mask_file, squeeze=False)\n    mask = _fix_mask_shape(mask_file, mask)\n    if not native_dtype:\n        mask = _to_dtype(mask, mask_dtype)\n    return mask\n</code></pre>"},{"location":"python/api/steinbock.io/#steinbock.io.read_neighbors","title":"<code>read_neighbors(neighbors_file)</code>","text":"Source code in <code>steinbock/io.py</code> <pre><code>def read_neighbors(neighbors_file: Union[str, PathLike]) -&gt; pd.DataFrame:\n    return pd.read_csv(\n        neighbors_file,\n        sep=\",|;\",\n        usecols=[\"Object\", \"Neighbor\", \"Distance\"],\n        dtype={\n            \"Object\": mask_dtype,\n            \"Neighbor\": mask_dtype,\n            \"Distance\": np.float32,\n        },\n        engine=\"python\",\n    )\n</code></pre>"},{"location":"python/api/steinbock.io/#steinbock.io.read_panel","title":"<code>read_panel(panel_file, unfiltered=False)</code>","text":"Source code in <code>steinbock/io.py</code> <pre><code>def read_panel(\n    panel_file: Union[str, PathLike], unfiltered: bool = False\n) -&gt; pd.DataFrame:\n    panel = pd.read_csv(\n        panel_file,\n        sep=\",|;\",\n        dtype={\n            \"channel\": pd.StringDtype(),\n            \"name\": pd.StringDtype(),\n            \"keep\": pd.BooleanDtype(),\n        },\n        engine=\"python\",\n        true_values=[\"1\"],\n        false_values=[\"0\"],\n    )\n    for required_col in (\"channel\", \"name\"):\n        if required_col not in panel:\n            raise SteinbockIOException(\n                f\"Missing '{required_col}' column in {panel_file}\"\n            )\n    for notnan_col in (\"channel\", \"keep\"):\n        if notnan_col in panel and panel[notnan_col].isna().any():\n            raise SteinbockIOException(\n                f\"Missing values for '{notnan_col}' in {panel_file}\"\n            )\n    for unique_col in (\"channel\", \"name\"):\n        if unique_col in panel:\n            if panel[unique_col].dropna().duplicated().any():\n                raise SteinbockIOException(\n                    f\"Duplicated values for '{unique_col}' in {panel_file}\"\n                )\n    if not unfiltered and \"keep\" in panel:\n        panel = panel.loc[panel[\"keep\"].astype(bool), :]\n    return panel\n</code></pre>"},{"location":"python/api/steinbock.io/#steinbock.io.write_data","title":"<code>write_data(data, data_file)</code>","text":"Source code in <code>steinbock/io.py</code> <pre><code>def write_data(data: pd.DataFrame, data_file: Union[str, PathLike]) -&gt; None:\n    data = data.reset_index()\n    data.to_csv(data_file, index=False)\n</code></pre>"},{"location":"python/api/steinbock.io/#steinbock.io.write_image","title":"<code>write_image(img, img_file, ignore_dtype=False)</code>","text":"Source code in <code>steinbock/io.py</code> <pre><code>def write_image(\n    img: np.ndarray,\n    img_file: Union[str, PathLike],\n    ignore_dtype: bool = False,\n) -&gt; None:\n    if not ignore_dtype:\n        img = _to_dtype(img, img_dtype)\n    tifffile.imwrite(\n        img_file,\n        data=img[np.newaxis, np.newaxis, :, :, :, np.newaxis],\n        imagej=img.dtype in (np.uint8, np.uint16, np.float32),\n    )\n</code></pre>"},{"location":"python/api/steinbock.io/#steinbock.io.write_image_info","title":"<code>write_image_info(image_info, image_info_file)</code>","text":"Source code in <code>steinbock/io.py</code> <pre><code>def write_image_info(\n    image_info: pd.DataFrame, image_info_file: Union[str, PathLike]\n) -&gt; None:\n    image_info.to_csv(image_info_file, index=False)\n</code></pre>"},{"location":"python/api/steinbock.io/#steinbock.io.write_mask","title":"<code>write_mask(mask, mask_file, ignore_dtype=False)</code>","text":"Source code in <code>steinbock/io.py</code> <pre><code>def write_mask(\n    mask: np.ndarray,\n    mask_file: Union[str, PathLike],\n    ignore_dtype: bool = False,\n) -&gt; None:\n    if not ignore_dtype:\n        mask = _to_dtype(mask, mask_dtype)\n    tifffile.imwrite(\n        mask_file,\n        data=mask[np.newaxis, np.newaxis, np.newaxis, :, :, np.newaxis],\n        imagej=mask.dtype in (np.uint8, np.uint16, np.float32),\n    )\n</code></pre>"},{"location":"python/api/steinbock.io/#steinbock.io.write_neighbors","title":"<code>write_neighbors(neighbors, neighbors_file)</code>","text":"Source code in <code>steinbock/io.py</code> <pre><code>def write_neighbors(\n    neighbors: pd.DataFrame, neighbors_file: Union[str, PathLike]\n) -&gt; None:\n    neighbors = neighbors.loc[:, [\"Object\", \"Neighbor\", \"Distance\"]].astype(\n        {\n            \"Object\": mask_dtype,\n            \"Neighbor\": mask_dtype,\n            \"Distance\": np.float32,\n        }\n    )\n    neighbors.to_csv(neighbors_file, index=False)\n</code></pre>"},{"location":"python/api/steinbock.io/#steinbock.io.write_panel","title":"<code>write_panel(panel, panel_file)</code>","text":"Source code in <code>steinbock/io.py</code> <pre><code>def write_panel(panel: pd.DataFrame, panel_file: Union[str, PathLike]) -&gt; None:\n    panel = panel.copy()\n    for col in panel.columns:\n        if panel[col].convert_dtypes().dtype == pd.BooleanDtype():\n            panel[col] = panel[col].astype(pd.UInt8Dtype())\n    panel.to_csv(panel_file, index=False)\n</code></pre>"},{"location":"python/api/steinbock.measurement/","title":"steinbock.measurement","text":""},{"location":"python/api/steinbock.measurement/#steinbock.measurement.cellprofiler","title":"<code>cellprofiler</code>  <code>special</code>","text":""},{"location":"python/api/steinbock.measurement/#steinbock.measurement.cellprofiler.data","title":"<code>data</code>  <code>special</code>","text":""},{"location":"python/api/steinbock.measurement/#steinbock.measurement.intensities","title":"<code>intensities</code>","text":""},{"location":"python/api/steinbock.measurement/#steinbock.measurement.intensities.logger","title":"<code>logger</code>","text":""},{"location":"python/api/steinbock.measurement/#steinbock.measurement.intensities.IntensityAggregation","title":"<code> IntensityAggregation            (Enum)         </code>","text":"<p>An enumeration.</p> Source code in <code>steinbock/measurement/intensities.py</code> <pre><code>class IntensityAggregation(Enum):\n    SUM = partial(scipy.ndimage.sum_labels)\n    MIN = partial(scipy.ndimage.minimum)\n    MAX = partial(scipy.ndimage.maximum)\n    MEAN = partial(scipy.ndimage.mean)\n    MEDIAN = partial(scipy.ndimage.median)\n    STD = partial(scipy.ndimage.standard_deviation)\n    VAR = partial(scipy.ndimage.variance)\n</code></pre>"},{"location":"python/api/steinbock.measurement/#steinbock.measurement.intensities.IntensityAggregation.MAX","title":"<code>MAX</code>","text":""},{"location":"python/api/steinbock.measurement/#steinbock.measurement.intensities.IntensityAggregation.MEAN","title":"<code>MEAN</code>","text":""},{"location":"python/api/steinbock.measurement/#steinbock.measurement.intensities.IntensityAggregation.MEDIAN","title":"<code>MEDIAN</code>","text":""},{"location":"python/api/steinbock.measurement/#steinbock.measurement.intensities.IntensityAggregation.MIN","title":"<code>MIN</code>","text":""},{"location":"python/api/steinbock.measurement/#steinbock.measurement.intensities.IntensityAggregation.STD","title":"<code>STD</code>","text":""},{"location":"python/api/steinbock.measurement/#steinbock.measurement.intensities.IntensityAggregation.SUM","title":"<code>SUM</code>","text":""},{"location":"python/api/steinbock.measurement/#steinbock.measurement.intensities.IntensityAggregation.VAR","title":"<code>VAR</code>","text":""},{"location":"python/api/steinbock.measurement/#steinbock.measurement.intensities.measure_intensites","title":"<code>measure_intensites(img, mask, channel_names, intensity_aggregation)</code>","text":"Source code in <code>steinbock/measurement/intensities.py</code> <pre><code>def measure_intensites(\n    img: np.ndarray,\n    mask: np.ndarray,\n    channel_names: Sequence[str],\n    intensity_aggregation: IntensityAggregation,\n) -&gt; pd.DataFrame:\n    object_ids = np.unique(mask[mask != 0])\n    data = {\n        channel_name: intensity_aggregation.value(img[i], labels=mask, index=object_ids)\n        for i, channel_name in enumerate(channel_names)\n    }\n    return pd.DataFrame(\n        data=data,\n        index=pd.Index(object_ids, dtype=io.mask_dtype, name=\"Object\"),\n    )\n</code></pre>"},{"location":"python/api/steinbock.measurement/#steinbock.measurement.intensities.try_measure_intensities_from_disk","title":"<code>try_measure_intensities_from_disk(img_files, mask_files, channel_names, intensity_aggregation, mmap=False)</code>","text":"Source code in <code>steinbock/measurement/intensities.py</code> <pre><code>def try_measure_intensities_from_disk(\n    img_files: Sequence[Union[str, PathLike]],\n    mask_files: Sequence[Union[str, PathLike]],\n    channel_names: Sequence[str],\n    intensity_aggregation: IntensityAggregation,\n    mmap: bool = False,\n) -&gt; Generator[Tuple[Path, Path, pd.DataFrame], None, None]:\n    for img_file, mask_file in zip(img_files, mask_files):\n        try:\n            if mmap:\n                img = io.mmap_image(img_file)\n                mask = io.mmap_mask(mask_file)\n            else:\n                img = io.read_image(img_file)\n                mask = io.read_mask(mask_file)\n            intensities = measure_intensites(\n                img, mask, channel_names, intensity_aggregation\n            )\n            del img, mask\n            yield Path(img_file), Path(mask_file), intensities\n            del intensities\n        except Exception as e:\n            logger.exception(f\"Error measuring intensities in {img_file}: {e}\")\n</code></pre>"},{"location":"python/api/steinbock.measurement/#steinbock.measurement.neighbors","title":"<code>neighbors</code>","text":""},{"location":"python/api/steinbock.measurement/#steinbock.measurement.neighbors.logger","title":"<code>logger</code>","text":""},{"location":"python/api/steinbock.measurement/#steinbock.measurement.neighbors.NeighborhoodType","title":"<code> NeighborhoodType            (Enum)         </code>","text":"<p>An enumeration.</p> Source code in <code>steinbock/measurement/neighbors.py</code> <pre><code>class NeighborhoodType(Enum):\n    CENTROID_DISTANCE = partial(_measure_centroid_distance_neighbors)\n    EUCLIDEAN_BORDER_DISTANCE = partial(_measure_euclidean_border_distance_neighbors)\n    EUCLIDEAN_PIXEL_EXPANSION = partial(_measure_euclidean_pixel_expansion_neighbors)\n</code></pre>"},{"location":"python/api/steinbock.measurement/#steinbock.measurement.neighbors.NeighborhoodType.CENTROID_DISTANCE","title":"<code>CENTROID_DISTANCE</code>","text":""},{"location":"python/api/steinbock.measurement/#steinbock.measurement.neighbors.NeighborhoodType.EUCLIDEAN_BORDER_DISTANCE","title":"<code>EUCLIDEAN_BORDER_DISTANCE</code>","text":""},{"location":"python/api/steinbock.measurement/#steinbock.measurement.neighbors.NeighborhoodType.EUCLIDEAN_PIXEL_EXPANSION","title":"<code>EUCLIDEAN_PIXEL_EXPANSION</code>","text":""},{"location":"python/api/steinbock.measurement/#steinbock.measurement.neighbors.SteinbockNeighborsMeasurementException","title":"<code> SteinbockNeighborsMeasurementException            (SteinbockMeasurementException)         </code>","text":"Source code in <code>steinbock/measurement/neighbors.py</code> <pre><code>class SteinbockNeighborsMeasurementException(SteinbockMeasurementException):\n    pass\n</code></pre>"},{"location":"python/api/steinbock.measurement/#steinbock.measurement.neighbors.measure_neighbors","title":"<code>measure_neighbors(mask, neighborhood_type, metric=None, dmax=None, kmax=None)</code>","text":"Source code in <code>steinbock/measurement/neighbors.py</code> <pre><code>def measure_neighbors(\n    mask: np.ndarray,\n    neighborhood_type: NeighborhoodType,\n    metric: Optional[str] = None,\n    dmax: Optional[float] = None,\n    kmax: Optional[int] = None,\n) -&gt; pd.DataFrame:\n    return neighborhood_type.value(mask, metric=metric, dmax=dmax, kmax=kmax)\n</code></pre>"},{"location":"python/api/steinbock.measurement/#steinbock.measurement.neighbors.try_measure_neighbors_from_disk","title":"<code>try_measure_neighbors_from_disk(mask_files, neighborhood_type, metric=None, dmax=None, kmax=None, mmap=False)</code>","text":"Source code in <code>steinbock/measurement/neighbors.py</code> <pre><code>def try_measure_neighbors_from_disk(\n    mask_files: Sequence[Union[str, PathLike]],\n    neighborhood_type: NeighborhoodType,\n    metric: Optional[str] = None,\n    dmax: Optional[float] = None,\n    kmax: Optional[int] = None,\n    mmap: bool = False,\n) -&gt; Generator[Tuple[Path, pd.DataFrame], None, None]:\n    for mask_file in mask_files:\n        try:\n            if mmap:\n                mask = io.mmap_mask(mask_file)\n            else:\n                mask = io.read_mask(mask_file)\n            neighbors = measure_neighbors(\n                mask, neighborhood_type, metric=metric, dmax=dmax, kmax=kmax\n            )\n            del mask\n            yield Path(mask_file), neighbors\n            del neighbors\n        except Exception as e:\n            logger.exception(f\"Error measuring neighbors in {mask_file}: {e}\")\n</code></pre>"},{"location":"python/api/steinbock.measurement/#steinbock.measurement.regionprops","title":"<code>regionprops</code>","text":""},{"location":"python/api/steinbock.measurement/#steinbock.measurement.regionprops.logger","title":"<code>logger</code>","text":""},{"location":"python/api/steinbock.measurement/#steinbock.measurement.regionprops.measure_regionprops","title":"<code>measure_regionprops(img, mask, skimage_regionprops)</code>","text":"Source code in <code>steinbock/measurement/regionprops.py</code> <pre><code>def measure_regionprops(\n    img: np.ndarray, mask: np.ndarray, skimage_regionprops: Sequence[str]\n) -&gt; pd.DataFrame:\n    skimage_regionprops = list(skimage_regionprops)\n    if \"label\" not in skimage_regionprops:\n        skimage_regionprops.insert(0, \"label\")\n    data = regionprops_table(\n        mask,\n        intensity_image=np.moveaxis(img, 0, -1),\n        properties=skimage_regionprops,\n    )\n    object_ids = data.pop(\"label\")\n    return pd.DataFrame(\n        data=data,\n        index=pd.Index(object_ids, dtype=io.mask_dtype, name=\"Object\"),\n    )\n</code></pre>"},{"location":"python/api/steinbock.measurement/#steinbock.measurement.regionprops.try_measure_regionprops_from_disk","title":"<code>try_measure_regionprops_from_disk(img_files, mask_files, skimage_regionprops, mmap=False)</code>","text":"Source code in <code>steinbock/measurement/regionprops.py</code> <pre><code>def try_measure_regionprops_from_disk(\n    img_files: Sequence[Union[str, PathLike]],\n    mask_files: Sequence[Union[str, PathLike]],\n    skimage_regionprops: Sequence[str],\n    mmap: bool = False,\n) -&gt; Generator[Tuple[Path, Path, pd.DataFrame], None, None]:\n    for img_file, mask_file in zip(img_files, mask_files):\n        try:\n            if mmap:\n                img = io.mmap_image(img_file)\n                mask = io.mmap_mask(mask_file)\n            else:\n                img = io.read_image(img_file)\n                mask = io.read_mask(mask_file)\n            regionprops = measure_regionprops(img, mask, skimage_regionprops)\n            del img, mask\n            yield Path(img_file), Path(mask_file), regionprops\n            del regionprops\n        except Exception as e:\n            logger.exception(f\"Error measuring regionprops in {img_file}: {e}\")\n</code></pre>"},{"location":"python/api/steinbock.preprocessing/","title":"steinbock.preprocessing","text":""},{"location":"python/api/steinbock.preprocessing/#steinbock.preprocessing.external","title":"<code>external</code>","text":""},{"location":"python/api/steinbock.preprocessing/#steinbock.preprocessing.external.logger","title":"<code>logger</code>","text":""},{"location":"python/api/steinbock.preprocessing/#steinbock.preprocessing.external.SteinbockExternalPreprocessingException","title":"<code> SteinbockExternalPreprocessingException            (SteinbockPreprocessingException)         </code>","text":"Source code in <code>steinbock/preprocessing/external.py</code> <pre><code>class SteinbockExternalPreprocessingException(SteinbockPreprocessingException):\n    pass\n</code></pre>"},{"location":"python/api/steinbock.preprocessing/#steinbock.preprocessing.external.create_panel_from_image_files","title":"<code>create_panel_from_image_files(ext_img_files)</code>","text":"Source code in <code>steinbock/preprocessing/external.py</code> <pre><code>def create_panel_from_image_files(\n    ext_img_files: Sequence[Union[str, PathLike]]\n) -&gt; pd.DataFrame:\n    num_channels = None\n    for ext_img_file in ext_img_files:\n        try:\n            ext_img = _read_external_image(ext_img_file)\n            num_channels = ext_img.shape[0]\n            break\n        except Exception:\n            pass  # skipped intentionally\n    if num_channels is None:\n        raise SteinbockExternalPreprocessingException(\"No valid images found\")\n    panel = pd.DataFrame(\n        data={\n            \"channel\": range(1, num_channels + 1),\n            \"name\": np.nan,\n            \"keep\": True,\n            \"ilastik\": range(1, num_channels + 1),\n            \"deepcell\": np.nan,\n            \"cellpose\": np.nan,\n        },\n    )\n    panel[\"channel\"] = panel[\"channel\"].astype(pd.StringDtype())\n    panel[\"name\"] = panel[\"name\"].astype(pd.StringDtype())\n    panel[\"keep\"] = panel[\"keep\"].astype(pd.BooleanDtype())\n    panel[\"ilastik\"] = panel[\"ilastik\"].astype(pd.UInt8Dtype())\n    panel[\"deepcell\"] = panel[\"deepcell\"].astype(pd.UInt8Dtype())\n    panel[\"cellpose\"] = panel[\"cellpose\"].astype(pd.UInt8Dtype())\n    return panel\n</code></pre>"},{"location":"python/api/steinbock.preprocessing/#steinbock.preprocessing.external.list_image_files","title":"<code>list_image_files(ext_img_dir)</code>","text":"Source code in <code>steinbock/preprocessing/external.py</code> <pre><code>def list_image_files(ext_img_dir: Union[str, PathLike]) -&gt; List[Path]:\n    return sorted(Path(ext_img_dir).rglob(\"[!.]*.*\"))\n</code></pre>"},{"location":"python/api/steinbock.preprocessing/#steinbock.preprocessing.external.try_preprocess_images_from_disk","title":"<code>try_preprocess_images_from_disk(ext_img_files)</code>","text":"Source code in <code>steinbock/preprocessing/external.py</code> <pre><code>def try_preprocess_images_from_disk(\n    ext_img_files: Sequence[Union[str, PathLike]]\n) -&gt; Generator[Tuple[Path, np.ndarray], None, None]:\n    for ext_img_file in ext_img_files:\n        try:\n            img = _read_external_image(ext_img_file)\n        except Exception:\n            logger.warning(f\"Unsupported file format: {ext_img_file}\")\n            continue\n        yield Path(ext_img_file), img\n        del img\n</code></pre>"},{"location":"python/api/steinbock.preprocessing/#steinbock.preprocessing.imc","title":"<code>imc</code>","text":""},{"location":"python/api/steinbock.preprocessing/#steinbock.preprocessing.imc.imc_available","title":"<code>imc_available</code>","text":""},{"location":"python/api/steinbock.preprocessing/#steinbock.preprocessing.imc.logger","title":"<code>logger</code>","text":""},{"location":"python/api/steinbock.preprocessing/#steinbock.preprocessing.imc.SteinbockIMCPreprocessingException","title":"<code> SteinbockIMCPreprocessingException            (SteinbockPreprocessingException)         </code>","text":"Source code in <code>steinbock/preprocessing/imc.py</code> <pre><code>class SteinbockIMCPreprocessingException(SteinbockPreprocessingException):\n    pass\n</code></pre>"},{"location":"python/api/steinbock.preprocessing/#steinbock.preprocessing.imc.create_image_info","title":"<code>create_image_info(mcd_txt_file, acquisition, img, recovery_file, recovered, img_file)</code>","text":"Source code in <code>steinbock/preprocessing/imc.py</code> <pre><code>def create_image_info(\n    mcd_txt_file: Union[str, PathLike],\n    acquisition: Optional[Acquisition],\n    img: np.ndarray,\n    recovery_file: Union[str, PathLike, None],\n    recovered: bool,\n    img_file: Union[str, PathLike],\n) -&gt; Dict[str, Any]:\n    recovery_file_name = None\n    if recovery_file is not None:\n        recovery_file_name = Path(recovery_file).name\n    image_info_row = {\n        \"image\": Path(img_file).name,\n        \"width_px\": img.shape[2],\n        \"height_px\": img.shape[1],\n        \"num_channels\": img.shape[0],\n        \"source_file\": Path(mcd_txt_file).name,\n        \"recovery_file\": recovery_file_name,\n        \"recovered\": recovered,\n    }\n    if acquisition is not None:\n        image_info_row.update(\n            {\n                \"acquisition_id\": acquisition.id,\n                \"acquisition_description\": acquisition.description,\n                \"acquisition_start_x_um\": (acquisition.roi_points_um[0][0]),\n                \"acquisition_start_y_um\": (acquisition.roi_points_um[0][1]),\n                \"acquisition_end_x_um\": (acquisition.roi_points_um[2][0]),\n                \"acquisition_end_y_um\": (acquisition.roi_points_um[2][1]),\n                \"acquisition_width_um\": acquisition.width_um,\n                \"acquisition_height_um\": acquisition.height_um,\n            }\n        )\n    return image_info_row\n</code></pre>"},{"location":"python/api/steinbock.preprocessing/#steinbock.preprocessing.imc.create_panel_from_imc_panel","title":"<code>create_panel_from_imc_panel(imc_panel_file, imc_panel_channel_col='Metal Tag', imc_panel_name_col='Target', imc_panel_keep_col='full', imc_panel_ilastik_col='ilastik')</code>","text":"Source code in <code>steinbock/preprocessing/imc.py</code> <pre><code>def create_panel_from_imc_panel(\n    imc_panel_file: Union[str, PathLike],\n    imc_panel_channel_col: str = \"Metal Tag\",\n    imc_panel_name_col: str = \"Target\",\n    imc_panel_keep_col: str = \"full\",\n    imc_panel_ilastik_col: str = \"ilastik\",\n) -&gt; pd.DataFrame:\n    imc_panel = pd.read_csv(\n        imc_panel_file,\n        sep=\",|;\",\n        dtype={\n            imc_panel_channel_col: pd.StringDtype(),\n            imc_panel_name_col: pd.StringDtype(),\n            imc_panel_keep_col: pd.BooleanDtype(),\n            imc_panel_ilastik_col: pd.BooleanDtype(),\n        },\n        engine=\"python\",\n        true_values=[\"1\"],\n        false_values=[\"0\"],\n    )\n    for required_col in (imc_panel_channel_col, imc_panel_name_col):\n        if required_col not in imc_panel:\n            raise SteinbockIMCPreprocessingException(\n                f\"Missing '{required_col}' column in IMC panel\"\n            )\n    for notnan_col in (\n        imc_panel_channel_col,\n        imc_panel_keep_col,\n        imc_panel_ilastik_col,\n    ):\n        if notnan_col in imc_panel and imc_panel[notnan_col].isna().any():\n            raise SteinbockIMCPreprocessingException(\n                f\"Missing values for '{notnan_col}' in IMC panel\"\n            )\n    rename_columns = {\n        imc_panel_channel_col: \"channel\",\n        imc_panel_name_col: \"name\",\n        imc_panel_keep_col: \"keep\",\n        imc_panel_ilastik_col: \"ilastik\",\n    }\n    drop_columns = [\n        panel_col\n        for imc_panel_col, panel_col in rename_columns.items()\n        if panel_col in imc_panel.columns and panel_col != imc_panel_col\n    ]\n    panel = imc_panel.drop(columns=drop_columns).rename(columns=rename_columns)\n    for _, g in panel.groupby(\"channel\"):\n        panel.loc[g.index, \"name\"] = \" / \".join(g[\"name\"].dropna().unique())\n        if \"keep\" in panel:\n            panel.loc[g.index, \"keep\"] = g[\"keep\"].any()\n        if \"ilastik\" in panel:\n            panel.loc[g.index, \"ilastik\"] = g[\"ilastik\"].any()\n    panel = panel.groupby(panel[\"channel\"].values).aggregate(\"first\")\n    panel = _clean_panel(panel)  # ilastik column may be nullable uint8 now\n    ilastik_mask = panel[\"ilastik\"].fillna(False).astype(bool)\n    panel[\"ilastik\"] = pd.Series(dtype=pd.UInt8Dtype())\n    panel.loc[ilastik_mask, \"ilastik\"] = range(1, ilastik_mask.sum() + 1)\n    return panel\n</code></pre>"},{"location":"python/api/steinbock.preprocessing/#steinbock.preprocessing.imc.create_panel_from_mcd_files","title":"<code>create_panel_from_mcd_files(mcd_files, unzip=False)</code>","text":"Source code in <code>steinbock/preprocessing/imc.py</code> <pre><code>def create_panel_from_mcd_files(\n    mcd_files: Sequence[Union[str, PathLike]], unzip: bool = False\n) -&gt; pd.DataFrame:\n    panels = []\n    for mcd_file in mcd_files:\n        zip_file_mcd_member = _get_zip_file_member(mcd_file)\n        if zip_file_mcd_member is None:\n            panels += create_panels_from_mcd_file(mcd_file)\n        elif unzip:\n            zip_file, mcd_member = zip_file_mcd_member\n            with ZipFile(zip_file) as fzip:\n                with TemporaryDirectory() as temp_dir:\n                    extracted_mcd_file = fzip.extract(mcd_member, path=temp_dir)\n                    panels += create_panels_from_mcd_file(extracted_mcd_file)\n    panel = pd.concat(panels, ignore_index=True, copy=False)\n    panel.drop_duplicates(inplace=True, ignore_index=True)\n    return _clean_panel(panel)\n</code></pre>"},{"location":"python/api/steinbock.preprocessing/#steinbock.preprocessing.imc.create_panel_from_txt_file","title":"<code>create_panel_from_txt_file(txt_file)</code>","text":"Source code in <code>steinbock/preprocessing/imc.py</code> <pre><code>def create_panel_from_txt_file(txt_file: Union[str, PathLike]) -&gt; pd.DataFrame:\n    with TXTFile(txt_file) as f:\n        return pd.DataFrame(\n            data={\n                \"channel\": pd.Series(data=f.channel_names, dtype=pd.StringDtype()),\n                \"name\": pd.Series(data=f.channel_labels, dtype=pd.StringDtype()),\n            },\n        )\n</code></pre>"},{"location":"python/api/steinbock.preprocessing/#steinbock.preprocessing.imc.create_panel_from_txt_files","title":"<code>create_panel_from_txt_files(txt_files, unzip=False)</code>","text":"Source code in <code>steinbock/preprocessing/imc.py</code> <pre><code>def create_panel_from_txt_files(\n    txt_files: Sequence[Union[str, PathLike]], unzip: bool = False\n) -&gt; pd.DataFrame:\n    panels = []\n    for txt_file in txt_files:\n        zip_file_txt_member = _get_zip_file_member(txt_file)\n        if zip_file_txt_member is None:\n            panel = create_panel_from_txt_file(txt_file)\n            panels.append(panel)\n        elif unzip:\n            zip_file, txt_member = zip_file_txt_member\n            with ZipFile(zip_file) as fzip:\n                with TemporaryDirectory() as temp_dir:\n                    extracted_txt_file = fzip.extract(txt_member, path=temp_dir)\n                    panel = create_panel_from_txt_file(extracted_txt_file)\n                    panels.append(panel)\n    panel = pd.concat(panels, ignore_index=True, copy=False)\n    panel.drop_duplicates(inplace=True, ignore_index=True)\n    return _clean_panel(panel)\n</code></pre>"},{"location":"python/api/steinbock.preprocessing/#steinbock.preprocessing.imc.create_panels_from_mcd_file","title":"<code>create_panels_from_mcd_file(mcd_file)</code>","text":"Source code in <code>steinbock/preprocessing/imc.py</code> <pre><code>def create_panels_from_mcd_file(mcd_file: Union[str, PathLike]) -&gt; List[pd.DataFrame]:\n    panels = []\n    with MCDFile(mcd_file) as f:\n        for slide in f.slides:\n            for acquisition in slide.acquisitions:\n                panel = pd.DataFrame(\n                    data={\n                        \"channel\": pd.Series(\n                            data=acquisition.channel_names,\n                            dtype=pd.StringDtype(),\n                        ),\n                        \"name\": pd.Series(\n                            data=acquisition.channel_labels,\n                            dtype=pd.StringDtype(),\n                        ),\n                    },\n                )\n                panels.append(panel)\n    return panels\n</code></pre>"},{"location":"python/api/steinbock.preprocessing/#steinbock.preprocessing.imc.filter_hot_pixels","title":"<code>filter_hot_pixels(img, thres)</code>","text":"Source code in <code>steinbock/preprocessing/imc.py</code> <pre><code>def filter_hot_pixels(img: np.ndarray, thres: float) -&gt; np.ndarray:\n    kernel = np.ones((1, 3, 3), dtype=bool)\n    kernel[0, 1, 1] = False\n    max_neighbor_img = maximum_filter(img, footprint=kernel, mode=\"mirror\")\n    return np.where(img - max_neighbor_img &gt; thres, max_neighbor_img, img)\n</code></pre>"},{"location":"python/api/steinbock.preprocessing/#steinbock.preprocessing.imc.list_mcd_files","title":"<code>list_mcd_files(mcd_dir, unzip=False)</code>","text":"Source code in <code>steinbock/preprocessing/imc.py</code> <pre><code>def list_mcd_files(mcd_dir: Union[str, PathLike], unzip: bool = False) -&gt; List[Path]:\n    mcd_files = sorted(Path(mcd_dir).rglob(\"[!.]*.mcd\"))\n    if unzip:\n        for zip_file in sorted(Path(mcd_dir).rglob(\"[!.]*.zip\")):\n            with ZipFile(zip_file) as fzip:\n                for zip_info in sorted(fzip.infolist(), key=lambda x: x.filename):\n                    if not zip_info.is_dir() and zip_info.filename.endswith(\".mcd\"):\n                        mcd_files.append(zip_file / zip_info.filename)\n    return mcd_files\n</code></pre>"},{"location":"python/api/steinbock.preprocessing/#steinbock.preprocessing.imc.list_txt_files","title":"<code>list_txt_files(txt_dir, unzip=False)</code>","text":"Source code in <code>steinbock/preprocessing/imc.py</code> <pre><code>def list_txt_files(txt_dir: Union[str, PathLike], unzip: bool = False) -&gt; List[Path]:\n    txt_files = sorted(Path(txt_dir).rglob(\"[!.]*.txt\"))\n    if unzip:\n        for zip_file in sorted(Path(txt_dir).rglob(\"[!.]*.zip\")):\n            with ZipFile(zip_file) as fzip:\n                for zip_info in sorted(fzip.infolist(), key=lambda x: x.filename):\n                    if not zip_info.is_dir() and zip_info.filename.endswith(\".txt\"):\n                        txt_files.append(zip_file / zip_info.filename)\n    return txt_files\n</code></pre>"},{"location":"python/api/steinbock.preprocessing/#steinbock.preprocessing.imc.preprocess_image","title":"<code>preprocess_image(img, hpf=None)</code>","text":"Source code in <code>steinbock/preprocessing/imc.py</code> <pre><code>def preprocess_image(img: np.ndarray, hpf: Optional[float] = None) -&gt; np.ndarray:\n    img = img.astype(np.float32)\n    if hpf is not None:\n        img = filter_hot_pixels(img, hpf)\n    return io._to_dtype(img, io.img_dtype)\n</code></pre>"},{"location":"python/api/steinbock.preprocessing/#steinbock.preprocessing.imc.try_preprocess_images_from_disk","title":"<code>try_preprocess_images_from_disk(mcd_files, txt_files, channel_names=None, hpf=None, unzip=False, strict=False)</code>","text":"Source code in <code>steinbock/preprocessing/imc.py</code> <pre><code>def try_preprocess_images_from_disk(\n    mcd_files: Sequence[Union[str, PathLike]],\n    txt_files: Sequence[Union[str, PathLike]],\n    channel_names: Optional[Sequence[str]] = None,\n    hpf: Optional[float] = None,\n    unzip: bool = False,\n    strict: bool = False,\n) -&gt; Generator[\n    Tuple[Path, Optional[\"Acquisition\"], np.ndarray, Optional[Path], bool],\n    None,\n    None,\n]:\n    candidate_txt_files = list(txt_files)\n    # process mcd files in reverse order to avoid ambiguous txt file matching\n    # see https://github.com/BodenmillerGroup/steinbock/issues/100\n    for mcd_file in sorted(\n        mcd_files, key=lambda mcd_file: Path(mcd_file).stem, reverse=True\n    ):\n        zip_file_mcd_member = _get_zip_file_member(mcd_file)\n        if zip_file_mcd_member is None:\n            for (\n                acquisition,\n                img,\n                recovery_txt_file,\n                recovered,\n            ) in _try_preprocess_mcd_images_from_disk(\n                mcd_file,\n                candidate_txt_files,\n                channel_names=channel_names,\n                hpf=hpf,\n                unzip=unzip,\n                strict=strict,\n            ):\n                yield Path(mcd_file), acquisition, img, recovery_txt_file, recovered\n                del img\n        elif unzip:\n            zip_file, mcd_member = zip_file_mcd_member\n            with ZipFile(zip_file) as fzip:\n                with TemporaryDirectory() as temp_dir:\n                    extracted_mcd_file = fzip.extract(mcd_member, path=temp_dir)\n                    for (\n                        acquisition,\n                        img,\n                        recovery_txt_file,\n                        recovered,\n                    ) in _try_preprocess_mcd_images_from_disk(\n                        extracted_mcd_file,\n                        candidate_txt_files,\n                        channel_names=channel_names,\n                        hpf=hpf,\n                        unzip=unzip,\n                        strict=strict,\n                    ):\n                        yield (\n                            Path(mcd_file),\n                            acquisition,\n                            img,\n                            recovery_txt_file,\n                            recovered,\n                        )\n                        del img\n    for txt_file in candidate_txt_files:\n        zip_file_txt_member = _get_zip_file_member(txt_file)\n        if zip_file_txt_member is None:\n            img = _try_preprocess_txt_image_from_disk(\n                txt_file, channel_names=channel_names, hpf=hpf\n            )\n            if img is not None:\n                yield Path(txt_file), None, img, None, False\n                del img\n        elif unzip:\n            zip_file, txt_member = zip_file_txt_member\n            with ZipFile(zip_file) as fzip:\n                with TemporaryDirectory() as temp_dir:\n                    extracted_txt_file = fzip.extract(txt_member, path=temp_dir)\n                    img = _try_preprocess_txt_image_from_disk(\n                        extracted_txt_file, channel_names=channel_names, hpf=hpf\n                    )\n                    if img is not None:\n                        yield Path(txt_file), None, img, None, False\n                        del img\n</code></pre>"},{"location":"python/api/steinbock.segmentation/","title":"steinbock.segmentation","text":""},{"location":"python/api/steinbock.segmentation/#steinbock.segmentation.cellpose","title":"<code>cellpose</code>","text":""},{"location":"python/api/steinbock.segmentation/#steinbock.segmentation.cellpose.cellpose_available","title":"<code>cellpose_available</code>","text":""},{"location":"python/api/steinbock.segmentation/#steinbock.segmentation.cellpose.logger","title":"<code>logger</code>","text":""},{"location":"python/api/steinbock.segmentation/#steinbock.segmentation.cellpose.AggregationFunction","title":"<code> AggregationFunction            (Protocol)         </code>","text":"Source code in <code>steinbock/segmentation/cellpose.py</code> <pre><code>class AggregationFunction(Protocol):\n    def __call__(self, img: np.ndarray, axis: Optional[int] = None) -&gt; np.ndarray:\n        ...\n</code></pre>"},{"location":"python/api/steinbock.segmentation/#steinbock.segmentation.cellpose.SteinbockCellposeSegmentationException","title":"<code> SteinbockCellposeSegmentationException            (SteinbockSegmentationException)         </code>","text":"Source code in <code>steinbock/segmentation/cellpose.py</code> <pre><code>class SteinbockCellposeSegmentationException(SteinbockSegmentationException):\n    pass\n</code></pre>"},{"location":"python/api/steinbock.segmentation/#steinbock.segmentation.cellpose.create_segmentation_stack","title":"<code>create_segmentation_stack(img, channelwise_minmax=False, channelwise_zscore=False, channel_groups=None, aggr_func=&lt;function mean at 0x7f3e49a62dc0&gt;)</code>","text":"Source code in <code>steinbock/segmentation/cellpose.py</code> <pre><code>def create_segmentation_stack(\n    img: np.ndarray,\n    channelwise_minmax: bool = False,\n    channelwise_zscore: bool = False,\n    channel_groups: Optional[np.ndarray] = None,\n    aggr_func: AggregationFunction = np.mean,\n) -&gt; np.ndarray:\n    if channelwise_minmax:\n        channel_mins = np.nanmin(img, axis=(1, 2))\n        channel_maxs = np.nanmax(img, axis=(1, 2))\n        channel_ranges = channel_maxs - channel_mins\n        img -= channel_mins[:, np.newaxis, np.newaxis]\n        img[channel_ranges &gt; 0] /= channel_ranges[\n            channel_ranges &gt; 0, np.newaxis, np.newaxis\n        ]\n    if channelwise_zscore:\n        channel_means = np.nanmean(img, axis=(1, 2))\n        channel_stds = np.nanstd(img, axis=(1, 2))\n        img -= channel_means[:, np.newaxis, np.newaxis]\n        img[channel_stds &gt; 0] /= channel_stds[channel_stds &gt; 0, np.newaxis, np.newaxis]\n    if channel_groups is not None:\n        img = np.stack(\n            [\n                aggr_func(img[channel_groups == channel_group], axis=0)\n                for channel_group in np.unique(channel_groups)\n                if not np.isnan(channel_group)\n            ]\n        )\n    return img\n</code></pre>"},{"location":"python/api/steinbock.segmentation/#steinbock.segmentation.cellpose.try_segment_objects","title":"<code>try_segment_objects(model_name, img_files, channelwise_minmax=False, channelwise_zscore=False, channel_groups=None, aggr_func=&lt;function mean at 0x7f3e49a62dc0&gt;, net_avg=True, batch_size=8, normalize=True, diameter=None, tile=False, tile_overlap=0.1, resample=True, interp=True, flow_threshold=0.4, cellprob_threshold=0.0, min_size=15)</code>","text":"Source code in <code>steinbock/segmentation/cellpose.py</code> <pre><code>def try_segment_objects(\n    model_name: str,\n    img_files: Sequence[Union[str, PathLike]],\n    channelwise_minmax: bool = False,\n    channelwise_zscore: bool = False,\n    channel_groups: Optional[np.ndarray] = None,\n    aggr_func: AggregationFunction = np.mean,\n    net_avg: bool = True,\n    batch_size: int = 8,\n    normalize: bool = True,\n    diameter: Optional[int] = None,\n    tile: bool = False,\n    tile_overlap: float = 0.1,\n    resample: bool = True,\n    interp: bool = True,\n    flow_threshold: float = 0.4,\n    cellprob_threshold: float = 0.0,\n    min_size: int = 15,\n) -&gt; Generator[Tuple[Path, np.ndarray, np.ndarray, np.ndarray, float], None, None]:\n    model = cellpose.models.Cellpose(model_type=model_name, net_avg=net_avg)\n    for img_file in img_files:\n        try:\n            img = create_segmentation_stack(\n                io.read_image(img_file),\n                channelwise_minmax=channelwise_minmax,\n                channelwise_zscore=channelwise_zscore,\n                channel_groups=channel_groups,\n                aggr_func=aggr_func,\n            )\n            # channels: [cytoplasmic, nuclear]\n            if img.shape[0] == 1:\n                channels = [0, 0]  # grayscale image (cytoplasmic channel only)\n            elif img.shape[0] == 2:\n                channels = [2, 1]  # R=1 G=2 B=3 image (nuclear &amp; cytoplasmic channels)\n            else:\n                raise SteinbockCellposeSegmentationException(\n                    f\"Invalid number of aggregated channels: \"\n                    f\"expected 1 or 2, got {img.shape[0]}\"\n                )\n            masks, flows, styles, diams = model.eval(\n                [img],\n                batch_size=batch_size,\n                channels=channels,\n                channel_axis=0,\n                normalize=normalize,\n                diameter=diameter,\n                net_avg=net_avg,\n                tile=tile,\n                tile_overlap=tile_overlap,\n                resample=resample,\n                interp=interp,\n                flow_threshold=flow_threshold,\n                cellprob_threshold=cellprob_threshold,\n                min_size=min_size,\n                progress=False,\n            )\n            diam = diams if isinstance(diams, float) else diams[0]\n            yield Path(img_file), masks[0], flows[0], styles[0], diam\n            del img, masks, flows, styles, diams\n        except Exception as e:\n            logger.exception(f\"Error segmenting objects in {img_file}: {e}\")\n</code></pre>"},{"location":"python/api/steinbock.segmentation/#steinbock.segmentation.cellprofiler","title":"<code>cellprofiler</code>  <code>special</code>","text":""},{"location":"python/api/steinbock.segmentation/#steinbock.segmentation.cellprofiler.data","title":"<code>data</code>  <code>special</code>","text":""},{"location":"python/api/steinbock.segmentation/#steinbock.segmentation.deepcell","title":"<code>deepcell</code>","text":""},{"location":"python/api/steinbock.segmentation/#steinbock.segmentation.deepcell.deepcell_available","title":"<code>deepcell_available</code>","text":""},{"location":"python/api/steinbock.segmentation/#steinbock.segmentation.deepcell.logger","title":"<code>logger</code>","text":""},{"location":"python/api/steinbock.segmentation/#steinbock.segmentation.deepcell.AggregationFunction","title":"<code> AggregationFunction            (Protocol)         </code>","text":"Source code in <code>steinbock/segmentation/deepcell.py</code> <pre><code>class AggregationFunction(Protocol):\n    def __call__(self, img: np.ndarray, axis: Optional[int] = None) -&gt; np.ndarray:\n        ...\n</code></pre>"},{"location":"python/api/steinbock.segmentation/#steinbock.segmentation.deepcell.Application","title":"<code> Application            (Enum)         </code>","text":"<p>An enumeration.</p> Source code in <code>steinbock/segmentation/deepcell.py</code> <pre><code>class Application(Enum):\n    MESMER = partial(_mesmer_application)\n</code></pre>"},{"location":"python/api/steinbock.segmentation/#steinbock.segmentation.deepcell.SteinbockDeepcellSegmentationException","title":"<code> SteinbockDeepcellSegmentationException            (SteinbockSegmentationException)         </code>","text":"Source code in <code>steinbock/segmentation/deepcell.py</code> <pre><code>class SteinbockDeepcellSegmentationException(SteinbockSegmentationException):\n    pass\n</code></pre>"},{"location":"python/api/steinbock.segmentation/#steinbock.segmentation.deepcell.create_segmentation_stack","title":"<code>create_segmentation_stack(img, channelwise_minmax=False, channelwise_zscore=False, channel_groups=None, aggr_func=&lt;function mean at 0x7f3e49a62dc0&gt;)</code>","text":"Source code in <code>steinbock/segmentation/deepcell.py</code> <pre><code>def create_segmentation_stack(\n    img: np.ndarray,\n    channelwise_minmax: bool = False,\n    channelwise_zscore: bool = False,\n    channel_groups: Optional[np.ndarray] = None,\n    aggr_func: AggregationFunction = np.mean,\n) -&gt; np.ndarray:\n    if channelwise_minmax:\n        channel_mins = np.nanmin(img, axis=(1, 2))\n        channel_maxs = np.nanmax(img, axis=(1, 2))\n        channel_ranges = channel_maxs - channel_mins\n        img -= channel_mins[:, np.newaxis, np.newaxis]\n        img[channel_ranges &gt; 0] /= channel_ranges[\n            channel_ranges &gt; 0, np.newaxis, np.newaxis\n        ]\n    if channelwise_zscore:\n        channel_means = np.nanmean(img, axis=(1, 2))\n        channel_stds = np.nanstd(img, axis=(1, 2))\n        img -= channel_means[:, np.newaxis, np.newaxis]\n        img[channel_stds &gt; 0] /= channel_stds[channel_stds &gt; 0, np.newaxis, np.newaxis]\n    if channel_groups is not None:\n        img = np.stack(\n            [\n                aggr_func(img[channel_groups == channel_group], axis=0)\n                for channel_group in np.unique(channel_groups)\n                if not np.isnan(channel_group)\n            ]\n        )\n    return img\n</code></pre>"},{"location":"python/api/steinbock.segmentation/#steinbock.segmentation.deepcell.try_segment_objects","title":"<code>try_segment_objects(img_files, application, model=None, channelwise_minmax=False, channelwise_zscore=False, channel_groups=None, aggr_func=&lt;function mean at 0x7f3e49a62dc0&gt;, **predict_kwargs)</code>","text":"Source code in <code>steinbock/segmentation/deepcell.py</code> <pre><code>def try_segment_objects(\n    img_files: Sequence[Union[str, PathLike]],\n    application: Application,\n    model: Optional[\"Model\"] = None,\n    channelwise_minmax: bool = False,\n    channelwise_zscore: bool = False,\n    channel_groups: Optional[np.ndarray] = None,\n    aggr_func: AggregationFunction = np.mean,\n    **predict_kwargs,\n) -&gt; Generator[Tuple[Path, np.ndarray], None, None]:\n    app, predict = application.value(model=model)\n    for img_file in img_files:\n        try:\n            img = create_segmentation_stack(\n                io.read_image(img_file),\n                channelwise_minmax=channelwise_minmax,\n                channelwise_zscore=channelwise_zscore,\n                channel_groups=channel_groups,\n                aggr_func=aggr_func,\n            )\n            if img.shape[0] != 2:\n                raise SteinbockDeepcellSegmentationException(\n                    f\"Invalid number of aggregated channels: \"\n                    f\"expected 2, got {img.shape[0]}\"\n                )\n            mask = predict(img, **predict_kwargs)\n            yield Path(img_file), mask\n            del img, mask\n        except Exception as e:\n            logger.exception(f\"Error segmenting objects in {img_file}: {e}\")\n</code></pre>"},{"location":"python/api/steinbock.utils/","title":"steinbock.utils","text":""},{"location":"python/api/steinbock.utils/#steinbock.utils.expansion","title":"<code>expansion</code>","text":""},{"location":"python/api/steinbock.utils/#steinbock.utils.expansion.expand_mask","title":"<code>expand_mask(mask, distance)</code>","text":"Source code in <code>steinbock/utils/expansion.py</code> <pre><code>def expand_mask(mask: np.ndarray, distance: int) -&gt; np.ndarray:\n    expanded_mask = expand_labels(mask, distance=distance)\n    return expanded_mask\n</code></pre>"},{"location":"python/api/steinbock.utils/#steinbock.utils.expansion.try_expand_masks_from_disk","title":"<code>try_expand_masks_from_disk(mask_files, distance, mmap=False)</code>","text":"Source code in <code>steinbock/utils/expansion.py</code> <pre><code>def try_expand_masks_from_disk(\n    mask_files: Sequence[Union[str, PathLike]], distance: int, mmap: bool = False\n) -&gt; Generator[Tuple[Path, np.ndarray], None, None]:\n    for mask_file in mask_files:\n        if mmap:\n            mask = io.mmap_mask(mask_file)\n        else:\n            mask = io.read_mask(mask_file, native_dtype=True)\n        expanded_mask = expand_mask(mask, distance=distance)\n        yield Path(mask_file), expanded_mask\n</code></pre>"},{"location":"python/api/steinbock.utils/#steinbock.utils.matching","title":"<code>matching</code>","text":""},{"location":"python/api/steinbock.utils/#steinbock.utils.matching.logger","title":"<code>logger</code>","text":""},{"location":"python/api/steinbock.utils/#steinbock.utils.matching.match_masks","title":"<code>match_masks(mask1, mask2)</code>","text":"Source code in <code>steinbock/utils/matching.py</code> <pre><code>def match_masks(mask1: np.ndarray, mask2: np.ndarray) -&gt; pd.DataFrame:\n    nz1 = mask1 != 0\n    nz2 = mask2 != 0\n    object_ids1 = []\n    object_ids2 = []\n    for object_id1 in np.unique(mask1[nz1]):\n        for object_id2 in np.unique(mask2[nz2 &amp; (mask1 == object_id1)]):\n            object_ids1.append(object_id1)\n            object_ids2.append(object_id2)\n    for object_id2 in np.unique(mask2[nz2]):\n        for object_id1 in np.unique(mask1[nz1 &amp; (mask2 == object_id2)]):\n            object_ids1.append(object_id1)\n            object_ids2.append(object_id2)\n    df = pd.DataFrame(data={\"Object1\": object_ids1, \"Object2\": object_ids2})\n    df.drop_duplicates(inplace=True, ignore_index=True)\n    return df\n</code></pre>"},{"location":"python/api/steinbock.utils/#steinbock.utils.matching.try_match_masks_from_disk","title":"<code>try_match_masks_from_disk(mask_files1, mask_files2, mmap=False)</code>","text":"Source code in <code>steinbock/utils/matching.py</code> <pre><code>def try_match_masks_from_disk(\n    mask_files1: Sequence[Union[str, PathLike]],\n    mask_files2: Sequence[Union[str, PathLike]],\n    mmap: bool = False,\n) -&gt; Generator[Tuple[Path, Path, pd.DataFrame], None, None]:\n    for mask_file1, mask_file2 in zip(mask_files1, mask_files2):\n        try:\n            if mmap:\n                mask1 = io.mmap_mask(mask_file1)\n                mask2 = io.mmap_mask(mask_file2)\n            else:\n                mask1 = io.read_mask(mask_file1)\n                mask2 = io.read_mask(mask_file2)\n            df = match_masks(mask1, mask2)\n            del mask1, mask2\n            yield Path(mask_file1), Path(mask_file2), df\n            del df\n        except Exception as e:\n            logger.exception(f\"Error matching masks {mask_file1, mask_file2}: {e}\")\n</code></pre>"},{"location":"python/api/steinbock.utils/#steinbock.utils.mosaics","title":"<code>mosaics</code>","text":""},{"location":"python/api/steinbock.utils/#steinbock.utils.mosaics.logger","title":"<code>logger</code>","text":""},{"location":"python/api/steinbock.utils/#steinbock.utils.mosaics.SteinbockMosaicsUtilsException","title":"<code> SteinbockMosaicsUtilsException            (SteinbockUtilsException)         </code>","text":"Source code in <code>steinbock/utils/mosaics.py</code> <pre><code>class SteinbockMosaicsUtilsException(SteinbockUtilsException):\n    pass\n</code></pre>"},{"location":"python/api/steinbock.utils/#steinbock.utils.mosaics.try_extract_tiles_from_disk_to_disk","title":"<code>try_extract_tiles_from_disk_to_disk(img_files, tile_dir, tile_size, mmap=False)</code>","text":"Source code in <code>steinbock/utils/mosaics.py</code> <pre><code>def try_extract_tiles_from_disk_to_disk(\n    img_files: Sequence[Union[str, PathLike]],\n    tile_dir: Union[str, PathLike],\n    tile_size: int,\n    mmap: bool = False,\n) -&gt; Generator[Tuple[Path, np.ndarray], None, None]:\n    for img_file in img_files:\n        try:\n            if mmap:\n                img = io.mmap_image(img_file)\n            else:\n                img = io.read_image(img_file, native_dtype=True)\n            if img.shape[-1] % tile_size == 1 or img.shape[-2] % tile_size == 1:\n                logger.warning(\n                    \"Chosen tile size yields UNSTITCHABLE tiles of 1 pixel \"\n                    f\"width or height for image {img_file}\"\n                )\n            for tile_x in range(0, img.shape[-1], tile_size):\n                for tile_y in range(0, img.shape[-2], tile_size):\n                    tile = img[\n                        :,\n                        tile_y : (tile_y + tile_size),\n                        tile_x : (tile_x + tile_size),\n                    ]\n                    tile_file = Path(tile_dir) / (\n                        f\"{Path(img_file).stem}_tx{tile_x}_ty{tile_y}\"\n                        f\"_tw{tile.shape[-1]}_th{tile.shape[-2]}.tiff\"\n                    )\n                    io.write_image(tile, tile_file, ignore_dtype=True)\n                    yield tile_file, tile\n                    del tile\n            del img\n        except Exception as e:\n            logger.exception(f\"Error extracting tiles: {img_file}: {e}\")\n</code></pre>"},{"location":"python/api/steinbock.utils/#steinbock.utils.mosaics.try_stitch_tiles_from_disk_to_disk","title":"<code>try_stitch_tiles_from_disk_to_disk(tile_files, img_dir, relabel=False, mmap=False)</code>","text":"Source code in <code>steinbock/utils/mosaics.py</code> <pre><code>def try_stitch_tiles_from_disk_to_disk(\n    tile_files: Sequence[Union[str, PathLike]],\n    img_dir: Union[str, PathLike],\n    relabel: bool = False,\n    mmap: bool = False,\n) -&gt; Generator[Tuple[Path, np.ndarray], None, None]:\n    class TileInfo(NamedTuple):\n        tile_file: Path\n        x: int\n        y: int\n        width: int\n        height: int\n\n    tile_file_stem_pattern = re.compile(\n        r\"(?P&lt;img_file_stem&gt;.+)_tx(?P&lt;x&gt;\\d+)_ty(?P&lt;y&gt;\\d+)\"\n        r\"_tw(?P&lt;width&gt;\\d+)_th(?P&lt;height&gt;\\d+)\"\n    )\n    img_tile_infos: Dict[str, List[TileInfo]] = {}\n    for tile_file in tile_files:\n        m = tile_file_stem_pattern.fullmatch(Path(tile_file).stem)\n        if m is None:\n            raise SteinbockMosaicsUtilsException(\n                f\"Malformed tile file name: {tile_file}\"\n            )\n        img_file_stem = m.group(\"img_file_stem\")\n        tile_info = TileInfo(\n            Path(tile_file),\n            int(m.group(\"x\")),\n            int(m.group(\"y\")),\n            int(m.group(\"width\")),\n            int(m.group(\"height\")),\n        )\n        if img_file_stem not in img_tile_infos:\n            img_tile_infos[img_file_stem] = []\n        img_tile_infos[img_file_stem].append(tile_info)\n    for img_file_stem, tile_infos in img_tile_infos.items():\n        img_file = Path(img_dir) / f\"{img_file_stem}.tiff\"\n        try:\n            tile = io.read_image(tile_infos[0].tile_file, native_dtype=True)\n            img_shape = (\n                tile.shape[0],\n                max(ti.y + ti.height for ti in tile_infos),\n                max(ti.x + ti.width for ti in tile_infos),\n            )\n            if mmap:\n                img = io.mmap_image(\n                    img_file, mode=\"r+\", shape=img_shape, dtype=tile.dtype\n                )\n            else:\n                img = np.zeros(img_shape, dtype=tile.dtype)\n            for i, tile_info in enumerate(tile_infos):\n                if i &gt; 0:\n                    tile = io.read_image(tile_info.tile_file, native_dtype=True)\n                img[\n                    :,\n                    tile_info.y : tile_info.y + tile_info.height,\n                    tile_info.x : tile_info.x + tile_info.width,\n                ] = tile\n                if mmap:\n                    img.flush()\n            if relabel:\n                img[0, :, :] = measure.label(img[0, :, :])\n            if mmap:\n                img.flush()\n            else:\n                io.write_image(img, img_file, ignore_dtype=True)\n            yield img_file, img\n            del img\n        except Exception as e:\n            logger.exception(f\"Error stitching tiles: {img_file}: {e}\")\n</code></pre>"},{"location":"python/api/steinbock.visualization/","title":"steinbock.visualization","text":""},{"location":"python/api/steinbock.visualization/#steinbock.visualization.view","title":"<code>view(img, masks=None, channel_names=None, pixel_size_um=1.0, run=True, **viewer_kwargs)</code>","text":"Source code in <code>steinbock/visualization.py</code> <pre><code>def view(\n    img: np.ndarray,\n    masks: Optional[Dict[str, np.ndarray]] = None,\n    channel_names: Optional[Sequence[str]] = None,\n    pixel_size_um: float = 1.0,\n    run: bool = True,\n    **viewer_kwargs,\n) -&gt; Optional[napari.Viewer]:\n    viewer = napari.Viewer(**viewer_kwargs)\n    viewer.axes.visible = True\n    viewer.dims.axis_labels = (\"y\", \"x\")\n    viewer.scale_bar.visible = True\n    viewer.scale_bar.unit = \"um\"\n    viewer.add_image(\n        data=img,\n        channel_axis=0,\n        colormap=\"gray\",\n        name=channel_names,\n        scale=(pixel_size_um, pixel_size_um),\n        blending=\"additive\",\n        visible=False,\n    )\n    if masks is not None:\n        for mask_name, mask in masks.items():\n            viewer.add_labels(\n                data=mask,\n                name=mask_name,\n                scale=(pixel_size_um, pixel_size_um),\n                blending=\"translucent\",\n                visible=False,\n            )\n    if run:\n        napari.run()\n        return None\n    return viewer\n</code></pre>"}]}